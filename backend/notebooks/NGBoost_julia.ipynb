{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66790ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cbd1f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngboost import NGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8909939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.read_pickle('../data/pkl/X_1000.pkl')\n",
    "# y = pd.read_pickle('../data/pkl/y_1000.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6c4d4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6558"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_pickle('../data/pkl/X_basic_rolling_df_5yrs_preprocessed.pkl')\n",
    "y = pd.read_pickle('../data/pkl/y_basic_rolling_df_5yrs_preprocessed.pkl')\n",
    "X.shape\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fe75380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac5d1790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an NGBoost model with a Gaussian process as the probabilistic model\n",
    "ngb = NGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae6bff19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=4.0927 val_loss=0.0000 scale=1.0000 norm=11.5720\n",
      "[iter 100] loss=4.0153 val_loss=0.0000 scale=1.0000 norm=10.7708\n",
      "[iter 200] loss=3.9736 val_loss=0.0000 scale=1.0000 norm=10.3654\n",
      "[iter 300] loss=3.9402 val_loss=0.0000 scale=1.0000 norm=10.0928\n",
      "[iter 400] loss=3.9152 val_loss=0.0000 scale=1.0000 norm=9.8925\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NGBRegressor(random_state=RandomState(MT19937) at 0x7FE7ADB65340)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NGBRegressor</label><div class=\"sk-toggleable__content\"><pre>NGBRegressor(random_state=RandomState(MT19937) at 0x7FE7ADB65340)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Base: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(criterion=&#x27;friedman_mse&#x27;, max_depth=3)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(criterion=&#x27;friedman_mse&#x27;, max_depth=3)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "NGBRegressor(random_state=RandomState(MT19937) at 0x7FE7ADB65340)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "ngb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1323f7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 169.37\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the testing data\n",
    "y_pred = ngb.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error of the predictions\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean squared error: {mse:.2f}\")\n",
    "\n",
    "# # Get uncertainty estimates for the predictions\n",
    "y_dist = ngb.pred_dist(X_test)\n",
    "\n",
    "\n",
    "# # Print the mean and standard deviation of the uncertainty estimates\n",
    "# print(f\"Mean standard deviation: {std_dev.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bbe526a-99f3-4d62-b6e3-73361001868d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loc': array([-0.50497451, -1.75557745,  8.0820651 , ...,  2.2523823 ,\n",
       "         0.62653525, -3.13603525]),\n",
       " 'scale': array([14.1339454 , 12.48868085, 13.05504079, ..., 11.36927199,\n",
       "        11.110834  , 12.85301136])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dist[0:].params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fc0055a-4a8b-4f6f-85ce-3024596c4901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0cfdea3-4473-4803-bb77-3d74f746bdaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y_dist[0:].params['loc'], kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10067099-dc2a-4fe8-a3ee-f9bf4a38b853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y_dist[0:].params['scale'], kde=True, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "597a26a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.528048780487805"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6546ce8d-36ec-4412-822e-a41a2b27888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_loc = ngb.feature_importances_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b9ffc09-11ac-49b2-9371-feaa235d55b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_scale = ngb.feature_importances_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6627c2ed-426a-4c6b-84d0-cffb2fe6e5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_feature_dict = dict(zip(X.columns, feature_importance_loc ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1c9a952-83af-410a-bb6c-4bd52633bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_feature_dict = dict(zip(X.columns, feature_importance_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6eed9aa8-33b5-4a1e-9f31-90d06f0b1b9a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FG_PCT_rolling_h': 0.11391106122160698,\n",
       " 'FG_PCT_rolling_a': 0.11227961821455913,\n",
       " 'REB_rolling_h': 0.09552685976844132,\n",
       " 'DREB_rolling_a': 0.093689020761687,\n",
       " 'FG3_PCT_rolling_h': 0.07707354791276157,\n",
       " 'TOV_rolling_a': 0.0702726930678369,\n",
       " 'TOV_rolling_h': 0.05757631174732492,\n",
       " 'FG3_PCT_rolling_a': 0.056892493197112835,\n",
       " 'DREB_rolling_h': 0.055723321861222384,\n",
       " 'STL_rolling_h': 0.048453064142738374,\n",
       " 'STL_rolling_a': 0.036083952904733506,\n",
       " 'REB_rolling_a': 0.028109986818006517,\n",
       " 'FT_PCT_rolling_a': 0.024178777025904524,\n",
       " 'AST_rolling_a': 0.02076015383527944,\n",
       " 'FT_PCT_rolling_h': 0.01960327188596753,\n",
       " 'PF_rolling_h': 0.016739511982482844,\n",
       " 'AST_rolling_h': 0.014721904063117673,\n",
       " 'BLK_rolling_h': 0.009965247963072646,\n",
       " 'BLK_rolling_a': 0.009144313408309053,\n",
       " 'TEAM_ABBREVIATION_HOU_h': 0.008059631428782727,\n",
       " 'OREB_rolling_h': 0.005821519402569732,\n",
       " 'PF_rolling_a': 0.004154856107156594,\n",
       " 'TEAM_ABBREVIATION_UTA_h': 0.003006047969326126,\n",
       " 'TEAM_ABBREVIATION_CHI_h': 0.002984092955758459,\n",
       " 'TEAM_ABBREVIATION_SAS_a': 0.002088759968349801,\n",
       " 'OREB_rolling_a': 0.0018988466441352302,\n",
       " 'TEAM_ABBREVIATION_PHI_h': 0.0012290117248588757,\n",
       " 'TEAM_ABBREVIATION_POR_h': 0.0010527039647626197,\n",
       " 'TEAM_ABBREVIATION_POR_a': 0.0010038317544136465,\n",
       " 'TEAM_ABBREVIATION_NYK_h': 0.0009976991282456451,\n",
       " 'TEAM_ABBREVIATION_DEN_h': 0.0008601697827942584,\n",
       " 'TEAM_ABBREVIATION_ATL_a': 0.0007437333760296772,\n",
       " 'TEAM_ABBREVIATION_PHI_a': 0.0006470553772616509,\n",
       " 'TEAM_ABBREVIATION_CLE_a': 0.0005183097008131654,\n",
       " 'TEAM_ABBREVIATION_LAC_h': 0.0004400003778140037,\n",
       " 'TEAM_ABBREVIATION_BOS_a': 0.000419794921570749,\n",
       " 'TEAM_ABBREVIATION_UTA_a': 0.0003968608746601095,\n",
       " 'TEAM_ABBREVIATION_PHX_a': 0.00036592368084021395,\n",
       " 'TEAM_ABBREVIATION_BKN_a': 0.0003629271883750447,\n",
       " 'TEAM_ABBREVIATION_ORL_h': 0.00032391823830483347,\n",
       " 'TEAM_ABBREVIATION_DAL_a': 0.00030651916884504656,\n",
       " 'TEAM_ABBREVIATION_MIL_h': 0.0002632486211296325,\n",
       " 'TEAM_ABBREVIATION_DAL_h': 0.00026231399231066487,\n",
       " 'TEAM_ABBREVIATION_MIA_h': 0.00023426991474946162,\n",
       " 'TEAM_ABBREVIATION_CHA_h': 0.00022947366191952972,\n",
       " 'TEAM_ABBREVIATION_NYK_a': 0.00018593528422214517,\n",
       " 'TEAM_ABBREVIATION_MEM_h': 0.0001831456612786026,\n",
       " 'TEAM_ABBREVIATION_NOP_a': 0.0001674079217992072,\n",
       " 'TEAM_ABBREVIATION_SAC_h': 8.68794247574056e-05,\n",
       " 'TEAM_ABBREVIATION_ATL_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_BKN_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_BOS_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_CLE_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_DET_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_GSW_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_IND_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_LAL_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_MIN_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_NOP_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_OKC_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_PHX_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_SAS_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_TOR_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_WAS_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_CHA_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_CHI_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_DEN_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_DET_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_GSW_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_HOU_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_IND_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_LAC_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_LAL_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_MEM_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_MIA_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_MIL_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_MIN_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_OKC_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_ORL_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_SAC_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_TOR_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_WAS_a': 0.0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(sorted(loc_feature_dict.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31a87b87-2190-4fbb-b15a-4c77a02e02fc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BLK_rolling_a': 0.0958964789214812,\n",
       " 'FT_PCT_rolling_h': 0.09252252928654726,\n",
       " 'OREB_rolling_a': 0.060570963554170694,\n",
       " 'REB_rolling_h': 0.05867814750836528,\n",
       " 'FG3_PCT_rolling_h': 0.05223094782123217,\n",
       " 'STL_rolling_a': 0.05220586047121887,\n",
       " 'FG3_PCT_rolling_a': 0.05142302157766366,\n",
       " 'PF_rolling_h': 0.04188754059284979,\n",
       " 'OREB_rolling_h': 0.04036467485630542,\n",
       " 'STL_rolling_h': 0.040051626691655726,\n",
       " 'DREB_rolling_h': 0.039590712044353674,\n",
       " 'FT_PCT_rolling_a': 0.034428069998425036,\n",
       " 'DREB_rolling_a': 0.0301134359179628,\n",
       " 'AST_rolling_h': 0.02962066414667911,\n",
       " 'TOV_rolling_a': 0.028118902275954927,\n",
       " 'TOV_rolling_h': 0.02776615704817869,\n",
       " 'FG_PCT_rolling_a': 0.027352593024270212,\n",
       " 'BLK_rolling_h': 0.026282587844761486,\n",
       " 'PF_rolling_a': 0.01792218860506461,\n",
       " 'TEAM_ABBREVIATION_MIA_a': 0.01743151132462761,\n",
       " 'REB_rolling_a': 0.01692746435353206,\n",
       " 'FG_PCT_rolling_h': 0.012834078782726696,\n",
       " 'TEAM_ABBREVIATION_LAC_h': 0.010071044525096952,\n",
       " 'AST_rolling_a': 0.009522132871632118,\n",
       " 'TEAM_ABBREVIATION_CHI_h': 0.009168668413110015,\n",
       " 'TEAM_ABBREVIATION_GSW_a': 0.006772058276642199,\n",
       " 'TEAM_ABBREVIATION_BKN_a': 0.0066926364236148195,\n",
       " 'TEAM_ABBREVIATION_DAL_a': 0.005776299466569066,\n",
       " 'TEAM_ABBREVIATION_CLE_a': 0.004408060520538985,\n",
       " 'TEAM_ABBREVIATION_LAL_a': 0.004208940387645228,\n",
       " 'TEAM_ABBREVIATION_SAS_a': 0.003829995777465282,\n",
       " 'TEAM_ABBREVIATION_HOU_h': 0.0037098525908271862,\n",
       " 'TEAM_ABBREVIATION_UTA_a': 0.0033335201899511793,\n",
       " 'TEAM_ABBREVIATION_BOS_h': 0.003051377714800461,\n",
       " 'TEAM_ABBREVIATION_HOU_a': 0.00303587899432016,\n",
       " 'TEAM_ABBREVIATION_NOP_a': 0.002984706662028405,\n",
       " 'TEAM_ABBREVIATION_ORL_h': 0.0025601503920816126,\n",
       " 'TEAM_ABBREVIATION_PHX_h': 0.002532693144349527,\n",
       " 'TEAM_ABBREVIATION_OKC_h': 0.002238785116682275,\n",
       " 'TEAM_ABBREVIATION_SAC_a': 0.0018983309816139272,\n",
       " 'TEAM_ABBREVIATION_POR_a': 0.0018542242171359297,\n",
       " 'TEAM_ABBREVIATION_POR_h': 0.0018237360535660657,\n",
       " 'TEAM_ABBREVIATION_SAC_h': 0.001758393401643413,\n",
       " 'TEAM_ABBREVIATION_WAS_a': 0.0014939216497833413,\n",
       " 'TEAM_ABBREVIATION_PHI_a': 0.0013994912428963295,\n",
       " 'TEAM_ABBREVIATION_OKC_a': 0.0013733768767604606,\n",
       " 'TEAM_ABBREVIATION_LAC_a': 0.0013235024316782774,\n",
       " 'TEAM_ABBREVIATION_ATL_a': 0.0013168975588612292,\n",
       " 'TEAM_ABBREVIATION_IND_a': 0.001154396389653814,\n",
       " 'TEAM_ABBREVIATION_BOS_a': 0.0011494701125290211,\n",
       " 'TEAM_ABBREVIATION_PHX_a': 0.0011018275475208426,\n",
       " 'TEAM_ABBREVIATION_CHA_a': 0.0008307427342885881,\n",
       " 'TEAM_ABBREVIATION_GSW_h': 0.0007946379458541522,\n",
       " 'TEAM_ABBREVIATION_DEN_h': 0.0005619656180884281,\n",
       " 'TEAM_ABBREVIATION_DAL_h': 0.0005481921954916699,\n",
       " 'TEAM_ABBREVIATION_NYK_h': 0.000391486382337563,\n",
       " 'TEAM_ABBREVIATION_TOR_a': 0.00033807407654907947,\n",
       " 'TEAM_ABBREVIATION_MEM_a': 0.00032617442233070837,\n",
       " 'TEAM_ABBREVIATION_CHA_h': 0.0002253665807278014,\n",
       " 'TEAM_ABBREVIATION_SAS_h': 0.00011567298323810807,\n",
       " 'TEAM_ABBREVIATION_MEM_h': 8.645128269474302e-05,\n",
       " 'TEAM_ABBREVIATION_BKN_h': 1.6709199374255622e-05,\n",
       " 'TEAM_ABBREVIATION_ATL_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_CLE_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_DET_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_IND_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_LAL_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_MIA_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_MIL_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_MIN_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_NOP_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_PHI_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_TOR_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_UTA_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_WAS_h': 0.0,\n",
       " 'TEAM_ABBREVIATION_CHI_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_DEN_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_DET_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_MIL_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_MIN_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_NYK_a': 0.0,\n",
       " 'TEAM_ABBREVIATION_ORL_a': 0.0}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(sorted(scale_feature_dict.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f660b52-087f-4402-95db-7a2b456159d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loc = pd.DataFrame({'feature':X.columns,\n",
    "                       'importance':feature_importance_loc})\\\n",
    "    .sort_values('importance',ascending=False)\n",
    "df_scale = pd.DataFrame({'feature':X.columns,\n",
    "                       'importance':feature_importance_scale})\\\n",
    "    .sort_values('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a888bff-f141-456f-b1ad-60d86445bbe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'scale param')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1300x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13,6))\n",
    "fig.suptitle(\"Feature importance plot for distribution parameters\", fontsize=17)\n",
    "sns.barplot(x='importance',y='feature',ax=ax1,data=df_loc.head(10), color=\"skyblue\").set_title('loc param')\n",
    "sns.barplot(x='importance',y='feature',ax=ax2,data=df_scale.head(10), color=\"skyblue\").set_title('scale param')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b0288f8-8c51-471e-b108-ac8f928d25b4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "  Using cached shap-0.41.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (572 kB)\n",
      "Requirement already satisfied: scikit-learn in /home/itcwork66/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from shap) (1.2.1)\n",
      "Collecting slicer==0.0.7\n",
      "  Using cached slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Collecting cloudpickle\n",
      "  Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /home/itcwork66/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from shap) (4.65.0)\n",
      "Requirement already satisfied: pandas in /home/itcwork66/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from shap) (1.5.3)\n",
      "Requirement already satisfied: numpy in /home/itcwork66/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from shap) (1.24.2)\n",
      "Requirement already satisfied: packaging>20.9 in /home/itcwork66/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from shap) (23.0)\n",
      "Collecting numba\n",
      "  Using cached numba-0.56.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "Requirement already satisfied: scipy in /home/itcwork66/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from shap) (1.10.1)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "Requirement already satisfied: setuptools in /home/itcwork66/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from numba->shap) (63.2.0)\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Using cached llvmlite-0.39.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/itcwork66/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/itcwork66/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from pandas->shap) (2022.7.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/itcwork66/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from scikit-learn->shap) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/itcwork66/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from scikit-learn->shap) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/itcwork66/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
      "Installing collected packages: slicer, numpy, llvmlite, cloudpickle, numba, shap\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.2\n",
      "    Uninstalling numpy-1.24.2:\n",
      "      Successfully uninstalled numpy-1.24.2\n",
      "Successfully installed cloudpickle-2.2.1 llvmlite-0.39.1 numba-0.56.4 numpy-1.23.5 shap-0.41.0 slicer-0.0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fdede812-1ab9-4eb2-a413-17fd084e1dfd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /home/itcwork66/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /home/itcwork66/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from scipy) (1.23.5)\n",
      "Requirement already satisfied: numba in /home/itcwork66/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (0.56.4)\n",
      "Requirement already satisfied: numpy<1.24,>=1.18 in /home/itcwork66/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from numba) (1.23.5)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /home/itcwork66/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from numba) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /home/itcwork66/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from numba) (63.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy\n",
    "!pip install numba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ca4815-b3f7-4860-92de-f115d0995022",
   "metadata": {},
   "source": [
    "## Tuning the NGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "50e1eb6c-5883-4880-b68a-93b9653ac2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7b7c7c8e-b561-4193-9d84-99df0ed4a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7c54ea0b-86fc-493b-9779-847cba78368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngb_cv = NGBRegressor(n_estimators=500, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d6207ce3-6d9b-4b44-9ad6-9eb1f3142633",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = DecisionTreeRegressor(criterion='friedman_mse', max_depth=2)\n",
    "b2 = DecisionTreeRegressor(criterion='friedman_mse', max_depth=4)\n",
    "b3 = DecisionTreeRegressor(criterion='poisson', max_depth=2)\n",
    "b4 = DecisionTreeRegressor(criterion='poisson', max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "96208351-d9fc-4ca0-846a-e0d09bcd57a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'minibatch_frac': [0.3, 0.5, 1.0],\n",
    "    'Base': [b1, b2, b3, b4],\n",
    "    'natural_gradient': [True, False],\n",
    "    'learning_rate': [0.1, 0.01, 0.005, 0.001],\n",
    "    'tol': [0.0001, 0.0005, 0.001]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ba990b0a-b9cf-498a-8bd1-ad3385f40938",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(ngb_cv, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "539ef128-4c8b-4574-85d8-0e3526b7b660",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=4.0953 val_loss=0.0000 scale=1.0000 norm=11.6644\n",
      "[iter 100] loss=3.8995 val_loss=0.0000 scale=1.0000 norm=9.8845\n",
      "[iter 200] loss=3.8214 val_loss=0.0000 scale=1.0000 norm=9.1906\n",
      "[iter 300] loss=3.7692 val_loss=0.0000 scale=1.0000 norm=8.9262\n",
      "[iter 400] loss=3.7713 val_loss=0.0000 scale=1.0000 norm=9.1247\n",
      "[iter 0] loss=4.1019 val_loss=0.0000 scale=1.0000 norm=11.7933\n",
      "[iter 100] loss=3.8965 val_loss=0.0000 scale=1.0000 norm=9.8263\n",
      "[iter 200] loss=3.8426 val_loss=0.0000 scale=1.0000 norm=9.5245\n",
      "[iter 300] loss=3.7729 val_loss=0.0000 scale=1.0000 norm=9.0711\n",
      "[iter 400] loss=3.7406 val_loss=0.0000 scale=1.0000 norm=8.9223\n",
      "[iter 0] loss=4.1117 val_loss=0.0000 scale=1.0000 norm=12.0439\n",
      "[iter 100] loss=3.8686 val_loss=0.0000 scale=1.0000 norm=9.5778\n",
      "[iter 200] loss=3.8223 val_loss=0.0000 scale=1.0000 norm=9.3010\n",
      "[iter 300] loss=3.7595 val_loss=0.0000 scale=1.0000 norm=8.9005\n",
      "[iter 400] loss=3.7426 val_loss=0.0000 scale=1.0000 norm=8.9368\n",
      "[iter 0] loss=4.1104 val_loss=0.0000 scale=1.0000 norm=11.9046\n",
      "[iter 100] loss=3.8973 val_loss=0.0000 scale=1.0000 norm=9.8344\n",
      "[iter 200] loss=3.8345 val_loss=0.0000 scale=1.0000 norm=9.4835\n",
      "[iter 300] loss=3.7913 val_loss=0.0000 scale=1.0000 norm=9.0887\n",
      "[iter 400] loss=3.7482 val_loss=0.0000 scale=1.0000 norm=8.8256\n",
      "[iter 0] loss=4.1027 val_loss=0.0000 scale=1.0000 norm=11.7968\n",
      "[iter 100] loss=3.8885 val_loss=0.0000 scale=1.0000 norm=9.7134\n",
      "[iter 200] loss=3.8120 val_loss=0.0000 scale=1.0000 norm=9.2497\n",
      "[iter 300] loss=3.7994 val_loss=0.0000 scale=1.0000 norm=9.3859\n",
      "[iter 400] loss=3.7463 val_loss=0.0000 scale=1.0000 norm=8.9892\n",
      "[iter 0] loss=4.0953 val_loss=0.0000 scale=1.0000 norm=11.6644\n",
      "[iter 100] loss=3.8992 val_loss=0.0000 scale=1.0000 norm=9.8970\n",
      "[iter 200] loss=3.8177 val_loss=0.0000 scale=1.0000 norm=9.2111\n",
      "[iter 300] loss=3.7643 val_loss=0.0000 scale=1.0000 norm=8.9336\n",
      "[iter 400] loss=3.7728 val_loss=0.0000 scale=1.0000 norm=9.1742\n",
      "[iter 0] loss=4.1019 val_loss=0.0000 scale=1.0000 norm=11.7933\n",
      "[iter 100] loss=3.8927 val_loss=0.0000 scale=1.0000 norm=9.7975\n",
      "[iter 200] loss=3.8385 val_loss=0.0000 scale=1.0000 norm=9.4874\n",
      "[iter 300] loss=3.7792 val_loss=0.0000 scale=1.0000 norm=8.9955\n",
      "[iter 400] loss=3.7409 val_loss=0.0000 scale=1.0000 norm=8.9380\n",
      "[iter 0] loss=4.1117 val_loss=0.0000 scale=1.0000 norm=12.0439\n",
      "[iter 100] loss=3.8723 val_loss=0.0000 scale=1.0000 norm=9.6311\n",
      "[iter 200] loss=3.8235 val_loss=0.0000 scale=1.0000 norm=9.3591\n",
      "[iter 300] loss=3.7644 val_loss=0.0000 scale=1.0000 norm=8.8903\n",
      "[iter 400] loss=3.7447 val_loss=0.0000 scale=1.0000 norm=8.9522\n",
      "[iter 0] loss=4.1104 val_loss=0.0000 scale=1.0000 norm=11.9046\n",
      "[iter 100] loss=3.8945 val_loss=0.0000 scale=1.0000 norm=9.8037\n",
      "[iter 200] loss=3.8242 val_loss=0.0000 scale=1.0000 norm=9.4463\n",
      "[iter 300] loss=3.7787 val_loss=0.0000 scale=1.0000 norm=9.0750\n",
      "[iter 400] loss=3.7379 val_loss=0.0000 scale=1.0000 norm=8.9104\n",
      "[iter 0] loss=4.1027 val_loss=0.0000 scale=1.0000 norm=11.7968\n",
      "[iter 100] loss=3.8903 val_loss=0.0000 scale=1.0000 norm=9.6932\n",
      "[iter 200] loss=3.8184 val_loss=0.0000 scale=1.0000 norm=9.2857\n",
      "[iter 300] loss=3.8022 val_loss=0.0000 scale=1.0000 norm=9.4064\n",
      "[iter 400] loss=3.7471 val_loss=0.0000 scale=1.0000 norm=9.0478\n",
      "[iter 0] loss=4.0953 val_loss=0.0000 scale=1.0000 norm=11.6644\n",
      "[iter 100] loss=3.8978 val_loss=0.0000 scale=1.0000 norm=9.8854\n",
      "[iter 200] loss=3.8117 val_loss=0.0000 scale=1.0000 norm=9.1792\n",
      "[iter 300] loss=3.7608 val_loss=0.0000 scale=1.0000 norm=8.9083\n",
      "[iter 400] loss=3.7704 val_loss=0.0000 scale=1.0000 norm=9.2038\n",
      "[iter 0] loss=4.1019 val_loss=0.0000 scale=1.0000 norm=11.7933\n",
      "[iter 100] loss=3.8925 val_loss=0.0000 scale=1.0000 norm=9.7881\n",
      "[iter 200] loss=3.8383 val_loss=0.0000 scale=1.0000 norm=9.4973\n",
      "[iter 300] loss=3.7816 val_loss=0.0000 scale=1.0000 norm=9.0556\n",
      "[iter 400] loss=3.7381 val_loss=0.0000 scale=1.0000 norm=8.9074\n",
      "[iter 0] loss=4.1117 val_loss=0.0000 scale=1.0000 norm=12.0439\n",
      "[iter 100] loss=3.8738 val_loss=0.0000 scale=1.0000 norm=9.5926\n",
      "[iter 200] loss=3.8119 val_loss=0.0000 scale=1.0000 norm=9.2862\n",
      "[iter 300] loss=3.7534 val_loss=0.0000 scale=1.0000 norm=8.8713\n",
      "[iter 400] loss=3.7382 val_loss=0.0000 scale=1.0000 norm=8.9175\n",
      "[iter 0] loss=4.1104 val_loss=0.0000 scale=1.0000 norm=11.9046\n",
      "[iter 100] loss=3.9026 val_loss=0.0000 scale=1.0000 norm=9.8187\n",
      "[iter 200] loss=3.8318 val_loss=0.0000 scale=1.0000 norm=9.4896\n",
      "[iter 300] loss=3.7842 val_loss=0.0000 scale=1.0000 norm=9.0807\n",
      "[iter 400] loss=3.7410 val_loss=0.0000 scale=1.0000 norm=8.8357\n",
      "[iter 0] loss=4.1027 val_loss=0.0000 scale=1.0000 norm=11.7968\n",
      "[iter 100] loss=3.8898 val_loss=0.0000 scale=1.0000 norm=9.7179\n",
      "[iter 200] loss=3.8177 val_loss=0.0000 scale=1.0000 norm=9.3089\n",
      "[iter 300] loss=3.7997 val_loss=0.0000 scale=1.0000 norm=9.4019\n",
      "[iter 400] loss=3.7538 val_loss=0.0000 scale=1.0000 norm=9.0588\n",
      "[iter 0] loss=4.0953 val_loss=0.0000 scale=0.5000 norm=0.4916\n",
      "[iter 100] loss=4.0467 val_loss=0.0000 scale=0.5000 norm=0.4646\n",
      "[iter 200] loss=4.0163 val_loss=0.0000 scale=1.0000 norm=0.9029\n",
      "[iter 300] loss=3.9668 val_loss=0.0000 scale=0.5000 norm=0.4293\n",
      "[iter 400] loss=3.9789 val_loss=0.0000 scale=1.0000 norm=0.8584\n",
      "[iter 0] loss=4.1019 val_loss=0.0000 scale=0.5000 norm=0.4898\n",
      "[iter 100] loss=4.0318 val_loss=0.0000 scale=1.0000 norm=0.8968\n",
      "[iter 200] loss=4.0203 val_loss=0.0000 scale=0.5000 norm=0.4527\n",
      "[iter 300] loss=3.9800 val_loss=0.0000 scale=1.0000 norm=0.8584\n",
      "[iter 400] loss=3.9665 val_loss=0.0000 scale=0.5000 norm=0.4256\n",
      "[iter 0] loss=4.1117 val_loss=0.0000 scale=0.5000 norm=0.4894\n",
      "[iter 100] loss=4.0166 val_loss=0.0000 scale=0.5000 norm=0.4499\n",
      "[iter 200] loss=4.0081 val_loss=0.0000 scale=0.5000 norm=0.4534\n",
      "[iter 300] loss=3.9508 val_loss=0.0000 scale=0.5000 norm=0.4279\n",
      "[iter 400] loss=3.9602 val_loss=0.0000 scale=1.0000 norm=0.8428\n",
      "[iter 0] loss=4.1104 val_loss=0.0000 scale=0.5000 norm=0.4918\n",
      "[iter 100] loss=4.0334 val_loss=0.0000 scale=0.5000 norm=0.4605\n",
      "[iter 200] loss=3.9897 val_loss=0.0000 scale=1.0000 norm=0.8929\n",
      "[iter 300] loss=3.9550 val_loss=0.0000 scale=0.5000 norm=0.4214\n",
      "[iter 400] loss=3.9462 val_loss=0.0000 scale=1.0000 norm=0.8455\n",
      "[iter 0] loss=4.1027 val_loss=0.0000 scale=0.5000 norm=0.4908\n",
      "[iter 100] loss=4.0441 val_loss=0.0000 scale=0.5000 norm=0.4572\n",
      "[iter 200] loss=3.9998 val_loss=0.0000 scale=1.0000 norm=0.9020\n",
      "[iter 300] loss=3.9862 val_loss=0.0000 scale=0.5000 norm=0.4384\n",
      "[iter 400] loss=3.9697 val_loss=0.0000 scale=0.5000 norm=0.4332\n",
      "[iter 0] loss=4.0953 val_loss=0.0000 scale=0.5000 norm=0.4916\n",
      "[iter 100] loss=4.0435 val_loss=0.0000 scale=0.5000 norm=0.4648\n",
      "[iter 200] loss=4.0148 val_loss=0.0000 scale=0.5000 norm=0.4480\n",
      "[iter 300] loss=3.9704 val_loss=0.0000 scale=0.5000 norm=0.4310\n",
      "[iter 400] loss=3.9862 val_loss=0.0000 scale=0.5000 norm=0.4331\n",
      "[iter 0] loss=4.1019 val_loss=0.0000 scale=0.5000 norm=0.4898\n",
      "[iter 100] loss=4.0393 val_loss=0.0000 scale=0.5000 norm=0.4612\n",
      "[iter 200] loss=4.0176 val_loss=0.0000 scale=1.0000 norm=0.8985\n",
      "[iter 300] loss=3.9811 val_loss=0.0000 scale=1.0000 norm=0.8566\n",
      "[iter 400] loss=3.9622 val_loss=0.0000 scale=0.5000 norm=0.4249\n",
      "[iter 0] loss=4.1117 val_loss=0.0000 scale=0.5000 norm=0.4894\n",
      "[iter 100] loss=4.0143 val_loss=0.0000 scale=0.5000 norm=0.4475\n",
      "[iter 200] loss=4.0056 val_loss=0.0000 scale=0.5000 norm=0.4476\n",
      "[iter 300] loss=3.9518 val_loss=0.0000 scale=1.0000 norm=0.8455\n",
      "[iter 400] loss=3.9624 val_loss=0.0000 scale=1.0000 norm=0.8435\n",
      "[iter 0] loss=4.1104 val_loss=0.0000 scale=0.5000 norm=0.4918\n",
      "[iter 100] loss=4.0351 val_loss=0.0000 scale=0.5000 norm=0.4587\n",
      "[iter 200] loss=4.0005 val_loss=0.0000 scale=0.5000 norm=0.4473\n",
      "[iter 300] loss=3.9671 val_loss=0.0000 scale=0.5000 norm=0.4314\n",
      "[iter 400] loss=3.9516 val_loss=0.0000 scale=1.0000 norm=0.8505\n",
      "[iter 0] loss=4.1027 val_loss=0.0000 scale=0.5000 norm=0.4908\n",
      "[iter 100] loss=4.0498 val_loss=0.0000 scale=0.5000 norm=0.4657\n",
      "[iter 200] loss=4.0038 val_loss=0.0000 scale=0.5000 norm=0.4510\n",
      "[iter 300] loss=3.9902 val_loss=0.0000 scale=1.0000 norm=0.8796\n",
      "[iter 400] loss=3.9750 val_loss=0.0000 scale=0.5000 norm=0.4393\n",
      "[iter 0] loss=4.0953 val_loss=0.0000 scale=0.5000 norm=0.4916\n",
      "[iter 100] loss=4.0524 val_loss=0.0000 scale=0.5000 norm=0.4705\n",
      "[iter 200] loss=4.0183 val_loss=0.0000 scale=0.5000 norm=0.4435\n",
      "[iter 300] loss=3.9668 val_loss=0.0000 scale=1.0000 norm=0.8669\n",
      "[iter 400] loss=3.9818 val_loss=0.0000 scale=1.0000 norm=0.8593\n",
      "[iter 0] loss=4.1019 val_loss=0.0000 scale=0.5000 norm=0.4898\n",
      "[iter 100] loss=4.0353 val_loss=0.0000 scale=0.5000 norm=0.4588\n",
      "[iter 200] loss=4.0231 val_loss=0.0000 scale=0.5000 norm=0.4539\n",
      "[iter 300] loss=3.9772 val_loss=0.0000 scale=1.0000 norm=0.8551\n",
      "[iter 400] loss=3.9693 val_loss=0.0000 scale=1.0000 norm=0.8695\n",
      "[iter 0] loss=4.1117 val_loss=0.0000 scale=0.5000 norm=0.4894\n",
      "[iter 100] loss=4.0113 val_loss=0.0000 scale=0.5000 norm=0.4440\n",
      "[iter 200] loss=4.0014 val_loss=0.0000 scale=0.5000 norm=0.4479\n",
      "[iter 300] loss=3.9554 val_loss=0.0000 scale=1.0000 norm=0.8537\n",
      "[iter 400] loss=3.9583 val_loss=0.0000 scale=1.0000 norm=0.8338\n",
      "[iter 0] loss=4.1104 val_loss=0.0000 scale=0.5000 norm=0.4918\n",
      "[iter 100] loss=4.0383 val_loss=0.0000 scale=0.5000 norm=0.4633\n",
      "[iter 200] loss=3.9866 val_loss=0.0000 scale=1.0000 norm=0.8730\n",
      "[iter 300] loss=3.9597 val_loss=0.0000 scale=0.5000 norm=0.4279\n",
      "[iter 400] loss=3.9549 val_loss=0.0000 scale=1.0000 norm=0.8538\n",
      "[iter 0] loss=4.1027 val_loss=0.0000 scale=0.5000 norm=0.4908\n",
      "[iter 100] loss=4.0459 val_loss=0.0000 scale=0.5000 norm=0.4587\n",
      "[iter 200] loss=3.9934 val_loss=0.0000 scale=0.5000 norm=0.4419\n",
      "[iter 300] loss=3.9946 val_loss=0.0000 scale=1.0000 norm=0.8836\n",
      "[iter 400] loss=3.9773 val_loss=0.0000 scale=0.5000 norm=0.4361\n",
      "[iter 0] loss=4.0887 val_loss=0.0000 scale=1.0000 norm=11.5815\n",
      "[iter 100] loss=3.8849 val_loss=0.0000 scale=1.0000 norm=9.7163\n",
      "[iter 200] loss=3.8171 val_loss=0.0000 scale=1.0000 norm=9.2653\n",
      "[iter 300] loss=3.7535 val_loss=0.0000 scale=1.0000 norm=8.9370\n",
      "[iter 400] loss=3.7253 val_loss=0.0000 scale=1.0000 norm=8.8418\n",
      "[iter 0] loss=4.1079 val_loss=0.0000 scale=1.0000 norm=11.7758\n",
      "[iter 100] loss=3.8835 val_loss=0.0000 scale=1.0000 norm=9.6757\n",
      "[iter 200] loss=3.8111 val_loss=0.0000 scale=1.0000 norm=9.2674\n",
      "[iter 300] loss=3.7675 val_loss=0.0000 scale=1.0000 norm=9.0348\n",
      "[iter 400] loss=3.7226 val_loss=0.0000 scale=1.0000 norm=8.8575\n",
      "[iter 0] loss=4.1036 val_loss=0.0000 scale=1.0000 norm=11.8357\n",
      "[iter 100] loss=3.8723 val_loss=0.0000 scale=1.0000 norm=9.6188\n",
      "[iter 200] loss=3.7913 val_loss=0.0000 scale=1.0000 norm=9.0645\n",
      "[iter 300] loss=3.7480 val_loss=0.0000 scale=1.0000 norm=8.8826\n",
      "[iter 400] loss=3.7123 val_loss=0.0000 scale=1.0000 norm=8.7096\n",
      "[iter 0] loss=4.1035 val_loss=0.0000 scale=1.0000 norm=11.7229\n",
      "[iter 100] loss=3.8763 val_loss=0.0000 scale=1.0000 norm=9.6642\n",
      "[iter 200] loss=3.8017 val_loss=0.0000 scale=1.0000 norm=9.1855\n",
      "[iter 300] loss=3.7545 val_loss=0.0000 scale=1.0000 norm=8.9306\n",
      "[iter 400] loss=3.7071 val_loss=0.0000 scale=1.0000 norm=8.7180\n",
      "[iter 0] loss=4.1023 val_loss=0.0000 scale=1.0000 norm=11.7478\n",
      "[iter 100] loss=3.8809 val_loss=0.0000 scale=1.0000 norm=9.6914\n",
      "[iter 200] loss=3.7925 val_loss=0.0000 scale=1.0000 norm=9.0837\n",
      "[iter 300] loss=3.7653 val_loss=0.0000 scale=1.0000 norm=9.0948\n",
      "[iter 400] loss=3.7272 val_loss=0.0000 scale=1.0000 norm=8.8719\n",
      "[iter 0] loss=4.0887 val_loss=0.0000 scale=1.0000 norm=11.5815\n",
      "[iter 100] loss=3.8861 val_loss=0.0000 scale=1.0000 norm=9.7163\n",
      "[iter 200] loss=3.8181 val_loss=0.0000 scale=1.0000 norm=9.2412\n",
      "[iter 300] loss=3.7530 val_loss=0.0000 scale=1.0000 norm=8.8841\n",
      "[iter 400] loss=3.7274 val_loss=0.0000 scale=1.0000 norm=8.8466\n",
      "[iter 0] loss=4.1079 val_loss=0.0000 scale=1.0000 norm=11.7758\n",
      "[iter 100] loss=3.8809 val_loss=0.0000 scale=1.0000 norm=9.6516\n",
      "[iter 200] loss=3.8095 val_loss=0.0000 scale=1.0000 norm=9.2593\n",
      "[iter 300] loss=3.7642 val_loss=0.0000 scale=1.0000 norm=9.0152\n",
      "[iter 400] loss=3.7240 val_loss=0.0000 scale=1.0000 norm=8.8509\n",
      "[iter 0] loss=4.1036 val_loss=0.0000 scale=1.0000 norm=11.8357\n",
      "[iter 100] loss=3.8724 val_loss=0.0000 scale=1.0000 norm=9.6041\n",
      "[iter 200] loss=3.7921 val_loss=0.0000 scale=1.0000 norm=9.0536\n",
      "[iter 300] loss=3.7516 val_loss=0.0000 scale=1.0000 norm=8.8831\n",
      "[iter 400] loss=3.7116 val_loss=0.0000 scale=2.0000 norm=17.4401\n",
      "[iter 0] loss=4.1035 val_loss=0.0000 scale=1.0000 norm=11.7229\n",
      "[iter 100] loss=3.8758 val_loss=0.0000 scale=1.0000 norm=9.6488\n",
      "[iter 200] loss=3.8019 val_loss=0.0000 scale=1.0000 norm=9.1669\n",
      "[iter 300] loss=3.7597 val_loss=0.0000 scale=1.0000 norm=8.9415\n",
      "[iter 400] loss=3.7196 val_loss=0.0000 scale=1.0000 norm=8.7245\n",
      "[iter 0] loss=4.1023 val_loss=0.0000 scale=1.0000 norm=11.7478\n",
      "[iter 100] loss=3.8805 val_loss=0.0000 scale=1.0000 norm=9.6906\n",
      "[iter 200] loss=3.7946 val_loss=0.0000 scale=1.0000 norm=9.0820\n",
      "[iter 300] loss=3.7677 val_loss=0.0000 scale=2.0000 norm=18.1593\n",
      "[iter 400] loss=3.7304 val_loss=0.0000 scale=1.0000 norm=8.9075\n",
      "[iter 0] loss=4.0887 val_loss=0.0000 scale=1.0000 norm=11.5815\n",
      "[iter 100] loss=3.8846 val_loss=0.0000 scale=1.0000 norm=9.7168\n",
      "[iter 200] loss=3.8141 val_loss=0.0000 scale=1.0000 norm=9.2530\n",
      "[iter 300] loss=3.7549 val_loss=0.0000 scale=1.0000 norm=8.9195\n",
      "[iter 400] loss=3.7286 val_loss=0.0000 scale=1.0000 norm=8.8444\n",
      "[iter 0] loss=4.1079 val_loss=0.0000 scale=1.0000 norm=11.7758\n",
      "[iter 100] loss=3.8870 val_loss=0.0000 scale=1.0000 norm=9.7127\n",
      "[iter 200] loss=3.8120 val_loss=0.0000 scale=1.0000 norm=9.2901\n",
      "[iter 300] loss=3.7683 val_loss=0.0000 scale=1.0000 norm=9.0706\n",
      "[iter 400] loss=3.7263 val_loss=0.0000 scale=1.0000 norm=8.8874\n",
      "[iter 0] loss=4.1036 val_loss=0.0000 scale=1.0000 norm=11.8357\n",
      "[iter 100] loss=3.8721 val_loss=0.0000 scale=1.0000 norm=9.6082\n",
      "[iter 200] loss=3.7904 val_loss=0.0000 scale=1.0000 norm=9.0730\n",
      "[iter 300] loss=3.7501 val_loss=0.0000 scale=1.0000 norm=8.8487\n",
      "[iter 400] loss=3.7133 val_loss=0.0000 scale=1.0000 norm=8.7340\n",
      "[iter 0] loss=4.1035 val_loss=0.0000 scale=1.0000 norm=11.7229\n",
      "[iter 100] loss=3.8724 val_loss=0.0000 scale=1.0000 norm=9.6473\n",
      "[iter 200] loss=3.7961 val_loss=0.0000 scale=1.0000 norm=9.1470\n",
      "[iter 300] loss=3.7523 val_loss=0.0000 scale=1.0000 norm=8.9029\n",
      "[iter 400] loss=3.7064 val_loss=0.0000 scale=1.0000 norm=8.6876\n",
      "[iter 0] loss=4.1023 val_loss=0.0000 scale=1.0000 norm=11.7478\n",
      "[iter 100] loss=3.8827 val_loss=0.0000 scale=1.0000 norm=9.6725\n",
      "[iter 200] loss=3.7954 val_loss=0.0000 scale=1.0000 norm=9.0708\n",
      "[iter 300] loss=3.7694 val_loss=0.0000 scale=2.0000 norm=18.1805\n",
      "[iter 400] loss=3.7295 val_loss=0.0000 scale=1.0000 norm=8.8825\n",
      "[iter 0] loss=4.0887 val_loss=0.0000 scale=0.5000 norm=0.4880\n",
      "[iter 100] loss=4.0323 val_loss=0.0000 scale=0.5000 norm=0.4671\n",
      "[iter 200] loss=4.0027 val_loss=0.0000 scale=0.5000 norm=0.4487\n",
      "[iter 300] loss=3.9552 val_loss=0.0000 scale=1.0000 norm=0.8515\n",
      "[iter 400] loss=3.9585 val_loss=0.0000 scale=1.0000 norm=0.8405\n",
      "[iter 0] loss=4.1079 val_loss=0.0000 scale=0.5000 norm=0.5021\n",
      "[iter 100] loss=4.0336 val_loss=0.0000 scale=0.5000 norm=0.4623\n",
      "[iter 200] loss=4.0022 val_loss=0.0000 scale=0.5000 norm=0.4450\n",
      "[iter 300] loss=3.9692 val_loss=0.0000 scale=0.5000 norm=0.4322\n",
      "[iter 400] loss=3.9523 val_loss=0.0000 scale=1.0000 norm=0.8463\n",
      "[iter 0] loss=4.1036 val_loss=0.0000 scale=0.5000 norm=0.4960\n",
      "[iter 100] loss=4.0182 val_loss=0.0000 scale=0.5000 norm=0.4555\n",
      "[iter 200] loss=3.9824 val_loss=0.0000 scale=0.5000 norm=0.4375\n",
      "[iter 300] loss=3.9424 val_loss=0.0000 scale=1.0000 norm=0.8477\n",
      "[iter 400] loss=3.9505 val_loss=0.0000 scale=1.0000 norm=0.8349\n",
      "[iter 0] loss=4.1035 val_loss=0.0000 scale=0.5000 norm=0.4996\n",
      "[iter 100] loss=4.0256 val_loss=0.0000 scale=0.5000 norm=0.4572\n",
      "[iter 200] loss=3.9862 val_loss=0.0000 scale=0.5000 norm=0.4476\n",
      "[iter 300] loss=3.9503 val_loss=0.0000 scale=1.0000 norm=0.8493\n",
      "[iter 400] loss=3.9470 val_loss=0.0000 scale=1.0000 norm=0.8480\n",
      "[iter 0] loss=4.1023 val_loss=0.0000 scale=0.5000 norm=0.4949\n",
      "[iter 100] loss=4.0331 val_loss=0.0000 scale=0.5000 norm=0.4553\n",
      "[iter 200] loss=3.9850 val_loss=0.0000 scale=0.5000 norm=0.4430\n",
      "[iter 300] loss=3.9638 val_loss=0.0000 scale=1.0000 norm=0.8653\n",
      "[iter 400] loss=3.9571 val_loss=0.0000 scale=1.0000 norm=0.8451\n",
      "[iter 0] loss=4.0887 val_loss=0.0000 scale=0.5000 norm=0.4880\n",
      "[iter 100] loss=4.0321 val_loss=0.0000 scale=0.5000 norm=0.4674\n",
      "[iter 200] loss=4.0047 val_loss=0.0000 scale=1.0000 norm=0.9020\n",
      "[iter 300] loss=3.9573 val_loss=0.0000 scale=1.0000 norm=0.8563\n",
      "[iter 400] loss=3.9553 val_loss=0.0000 scale=1.0000 norm=0.8404\n",
      "[iter 0] loss=4.1079 val_loss=0.0000 scale=0.5000 norm=0.5021\n",
      "[iter 100] loss=4.0316 val_loss=0.0000 scale=1.0000 norm=0.9182\n",
      "[iter 200] loss=3.9999 val_loss=0.0000 scale=0.5000 norm=0.4424\n",
      "[iter 300] loss=3.9669 val_loss=0.0000 scale=1.0000 norm=0.8625\n",
      "[iter 400] loss=3.9534 val_loss=0.0000 scale=1.0000 norm=0.8513\n",
      "[iter 0] loss=4.1036 val_loss=0.0000 scale=0.5000 norm=0.4960\n",
      "[iter 100] loss=4.0188 val_loss=0.0000 scale=1.0000 norm=0.9070\n",
      "[iter 200] loss=3.9826 val_loss=0.0000 scale=0.5000 norm=0.4339\n",
      "[iter 300] loss=3.9433 val_loss=0.0000 scale=1.0000 norm=0.8515\n",
      "[iter 400] loss=3.9489 val_loss=0.0000 scale=1.0000 norm=0.8348\n",
      "[iter 0] loss=4.1035 val_loss=0.0000 scale=0.5000 norm=0.4996\n",
      "[iter 100] loss=4.0245 val_loss=0.0000 scale=1.0000 norm=0.9125\n",
      "[iter 200] loss=3.9840 val_loss=0.0000 scale=0.5000 norm=0.4476\n",
      "[iter 300] loss=3.9533 val_loss=0.0000 scale=0.5000 norm=0.4306\n",
      "[iter 400] loss=3.9509 val_loss=0.0000 scale=0.5000 norm=0.4254\n",
      "[iter 0] loss=4.1023 val_loss=0.0000 scale=0.5000 norm=0.4949\n",
      "[iter 100] loss=4.0313 val_loss=0.0000 scale=0.5000 norm=0.4536\n",
      "[iter 200] loss=3.9822 val_loss=0.0000 scale=1.0000 norm=0.8839\n",
      "[iter 300] loss=3.9596 val_loss=0.0000 scale=1.0000 norm=0.8555\n",
      "[iter 400] loss=3.9543 val_loss=0.0000 scale=1.0000 norm=0.8443\n",
      "[iter 0] loss=4.0887 val_loss=0.0000 scale=0.5000 norm=0.4880\n",
      "[iter 100] loss=4.0361 val_loss=0.0000 scale=0.5000 norm=0.4707\n",
      "[iter 200] loss=4.0085 val_loss=0.0000 scale=1.0000 norm=0.9110\n",
      "[iter 300] loss=3.9570 val_loss=0.0000 scale=1.0000 norm=0.8551\n",
      "[iter 400] loss=3.9603 val_loss=0.0000 scale=1.0000 norm=0.8446\n",
      "[iter 0] loss=4.1079 val_loss=0.0000 scale=0.5000 norm=0.5021\n",
      "[iter 100] loss=4.0312 val_loss=0.0000 scale=0.5000 norm=0.4609\n",
      "[iter 200] loss=3.9999 val_loss=0.0000 scale=0.5000 norm=0.4446\n",
      "[iter 300] loss=3.9657 val_loss=0.0000 scale=1.0000 norm=0.8643\n",
      "[iter 400] loss=3.9510 val_loss=0.0000 scale=1.0000 norm=0.8468\n",
      "[iter 0] loss=4.1036 val_loss=0.0000 scale=0.5000 norm=0.4960\n",
      "[iter 100] loss=4.0188 val_loss=0.0000 scale=0.5000 norm=0.4543\n",
      "[iter 200] loss=3.9850 val_loss=0.0000 scale=0.5000 norm=0.4382\n",
      "[iter 300] loss=3.9431 val_loss=0.0000 scale=0.5000 norm=0.4248\n",
      "[iter 400] loss=3.9473 val_loss=0.0000 scale=0.5000 norm=0.4136\n",
      "[iter 0] loss=4.1035 val_loss=0.0000 scale=0.5000 norm=0.4996\n",
      "[iter 100] loss=4.0238 val_loss=0.0000 scale=0.5000 norm=0.4566\n",
      "[iter 200] loss=3.9857 val_loss=0.0000 scale=0.5000 norm=0.4499\n",
      "[iter 300] loss=3.9512 val_loss=0.0000 scale=1.0000 norm=0.8566\n",
      "[iter 400] loss=3.9459 val_loss=0.0000 scale=0.5000 norm=0.4240\n",
      "[iter 0] loss=4.1023 val_loss=0.0000 scale=0.5000 norm=0.4949\n",
      "[iter 100] loss=4.0331 val_loss=0.0000 scale=0.5000 norm=0.4546\n",
      "[iter 200] loss=3.9849 val_loss=0.0000 scale=1.0000 norm=0.8892\n",
      "[iter 300] loss=3.9653 val_loss=0.0000 scale=1.0000 norm=0.8657\n",
      "[iter 400] loss=3.9563 val_loss=0.0000 scale=0.5000 norm=0.4209\n",
      "[iter 0] loss=4.0971 val_loss=0.0000 scale=1.0000 norm=11.6012\n",
      "[iter 100] loss=3.8869 val_loss=0.0000 scale=1.0000 norm=9.6535\n",
      "[iter 200] loss=3.8217 val_loss=0.0000 scale=2.0000 norm=18.4859\n",
      "[iter 300] loss=3.7740 val_loss=0.0000 scale=1.0000 norm=8.9661\n",
      "[iter 400] loss=3.7297 val_loss=0.0000 scale=1.0000 norm=8.7235\n",
      "[iter 0] loss=4.0972 val_loss=0.0000 scale=1.0000 norm=11.6172\n",
      "[iter 100] loss=3.8911 val_loss=0.0000 scale=2.0000 norm=19.4722\n",
      "[iter 200] loss=3.8261 val_loss=0.0000 scale=1.0000 norm=9.3247\n",
      "[iter 300] loss=3.7777 val_loss=0.0000 scale=1.0000 norm=9.0543\n",
      "[iter 400] loss=3.7373 val_loss=0.0000 scale=1.0000 norm=8.8288\n",
      "[iter 0] loss=4.0836 val_loss=0.0000 scale=1.0000 norm=11.5145\n",
      "[iter 100] loss=3.8821 val_loss=0.0000 scale=1.0000 norm=9.6578\n",
      "[iter 200] loss=3.8171 val_loss=0.0000 scale=1.0000 norm=9.2221\n",
      "[iter 300] loss=3.7682 val_loss=0.0000 scale=2.0000 norm=17.8567\n",
      "[iter 400] loss=3.7268 val_loss=0.0000 scale=1.0000 norm=8.7004\n",
      "[iter 0] loss=4.0930 val_loss=0.0000 scale=1.0000 norm=11.5486\n",
      "[iter 100] loss=3.8919 val_loss=0.0000 scale=1.0000 norm=9.7240\n",
      "[iter 200] loss=3.8281 val_loss=0.0000 scale=1.0000 norm=9.2957\n",
      "[iter 300] loss=3.7773 val_loss=0.0000 scale=1.0000 norm=8.9848\n",
      "[iter 400] loss=3.7350 val_loss=0.0000 scale=1.0000 norm=8.7420\n",
      "[iter 0] loss=4.0924 val_loss=0.0000 scale=1.0000 norm=11.5740\n",
      "[iter 100] loss=3.8872 val_loss=0.0000 scale=1.0000 norm=9.7127\n",
      "[iter 200] loss=3.8177 val_loss=0.0000 scale=1.0000 norm=9.2514\n",
      "[iter 300] loss=3.7711 val_loss=0.0000 scale=1.0000 norm=8.9693\n",
      "[iter 400] loss=3.7299 val_loss=0.0000 scale=1.0000 norm=8.7337\n",
      "[iter 0] loss=4.0971 val_loss=0.0000 scale=1.0000 norm=11.6012\n",
      "[iter 100] loss=3.8869 val_loss=0.0000 scale=1.0000 norm=9.6535\n",
      "[iter 200] loss=3.8217 val_loss=0.0000 scale=2.0000 norm=18.4859\n",
      "[iter 300] loss=3.7740 val_loss=0.0000 scale=1.0000 norm=8.9661\n",
      "[iter 400] loss=3.7297 val_loss=0.0000 scale=1.0000 norm=8.7235\n",
      "[iter 0] loss=4.0972 val_loss=0.0000 scale=1.0000 norm=11.6172\n",
      "[iter 100] loss=3.8911 val_loss=0.0000 scale=2.0000 norm=19.4722\n",
      "[iter 200] loss=3.8261 val_loss=0.0000 scale=1.0000 norm=9.3247\n",
      "[iter 300] loss=3.7777 val_loss=0.0000 scale=1.0000 norm=9.0543\n",
      "[iter 400] loss=3.7373 val_loss=0.0000 scale=1.0000 norm=8.8288\n",
      "[iter 0] loss=4.0836 val_loss=0.0000 scale=1.0000 norm=11.5145\n",
      "[iter 100] loss=3.8821 val_loss=0.0000 scale=1.0000 norm=9.6578\n",
      "[iter 200] loss=3.8171 val_loss=0.0000 scale=1.0000 norm=9.2221\n",
      "[iter 300] loss=3.7682 val_loss=0.0000 scale=2.0000 norm=17.8567\n",
      "[iter 400] loss=3.7268 val_loss=0.0000 scale=1.0000 norm=8.7004\n",
      "[iter 0] loss=4.0930 val_loss=0.0000 scale=1.0000 norm=11.5486\n",
      "[iter 100] loss=3.8919 val_loss=0.0000 scale=1.0000 norm=9.7240\n",
      "[iter 200] loss=3.8281 val_loss=0.0000 scale=1.0000 norm=9.2957\n",
      "[iter 300] loss=3.7773 val_loss=0.0000 scale=1.0000 norm=8.9848\n",
      "[iter 400] loss=3.7350 val_loss=0.0000 scale=1.0000 norm=8.7420\n",
      "[iter 0] loss=4.0924 val_loss=0.0000 scale=1.0000 norm=11.5740\n",
      "[iter 100] loss=3.8872 val_loss=0.0000 scale=1.0000 norm=9.7127\n",
      "[iter 200] loss=3.8177 val_loss=0.0000 scale=1.0000 norm=9.2514\n",
      "[iter 300] loss=3.7711 val_loss=0.0000 scale=1.0000 norm=8.9693\n",
      "[iter 400] loss=3.7299 val_loss=0.0000 scale=1.0000 norm=8.7337\n",
      "[iter 0] loss=4.0971 val_loss=0.0000 scale=1.0000 norm=11.6012\n",
      "[iter 100] loss=3.8869 val_loss=0.0000 scale=1.0000 norm=9.6535\n",
      "[iter 200] loss=3.8217 val_loss=0.0000 scale=2.0000 norm=18.4859\n",
      "[iter 300] loss=3.7740 val_loss=0.0000 scale=1.0000 norm=8.9661\n",
      "[iter 400] loss=3.7297 val_loss=0.0000 scale=1.0000 norm=8.7235\n",
      "[iter 0] loss=4.0972 val_loss=0.0000 scale=1.0000 norm=11.6172\n",
      "[iter 100] loss=3.8911 val_loss=0.0000 scale=2.0000 norm=19.4722\n",
      "[iter 200] loss=3.8261 val_loss=0.0000 scale=1.0000 norm=9.3247\n",
      "[iter 300] loss=3.7777 val_loss=0.0000 scale=1.0000 norm=9.0543\n",
      "[iter 400] loss=3.7373 val_loss=0.0000 scale=1.0000 norm=8.8288\n",
      "[iter 0] loss=4.0836 val_loss=0.0000 scale=1.0000 norm=11.5145\n",
      "[iter 100] loss=3.8821 val_loss=0.0000 scale=1.0000 norm=9.6578\n",
      "[iter 200] loss=3.8171 val_loss=0.0000 scale=1.0000 norm=9.2221\n",
      "[iter 300] loss=3.7682 val_loss=0.0000 scale=2.0000 norm=17.8567\n",
      "[iter 400] loss=3.7268 val_loss=0.0000 scale=1.0000 norm=8.7004\n",
      "[iter 0] loss=4.0930 val_loss=0.0000 scale=1.0000 norm=11.5486\n",
      "[iter 100] loss=3.8919 val_loss=0.0000 scale=1.0000 norm=9.7240\n",
      "[iter 200] loss=3.8281 val_loss=0.0000 scale=1.0000 norm=9.2957\n",
      "[iter 300] loss=3.7773 val_loss=0.0000 scale=1.0000 norm=8.9848\n",
      "[iter 400] loss=3.7350 val_loss=0.0000 scale=1.0000 norm=8.7420\n",
      "[iter 0] loss=4.0924 val_loss=0.0000 scale=1.0000 norm=11.5740\n",
      "[iter 100] loss=3.8872 val_loss=0.0000 scale=1.0000 norm=9.7127\n",
      "[iter 200] loss=3.8177 val_loss=0.0000 scale=1.0000 norm=9.2514\n",
      "[iter 300] loss=3.7711 val_loss=0.0000 scale=1.0000 norm=8.9693\n",
      "[iter 400] loss=3.7299 val_loss=0.0000 scale=1.0000 norm=8.7337\n",
      "[iter 0] loss=4.0971 val_loss=0.0000 scale=0.5000 norm=0.4963\n",
      "[iter 100] loss=4.0360 val_loss=0.0000 scale=0.5000 norm=0.4644\n",
      "[iter 200] loss=3.9989 val_loss=0.0000 scale=1.0000 norm=0.8921\n",
      "[iter 300] loss=3.9679 val_loss=0.0000 scale=1.0000 norm=0.8627\n",
      "[iter 400] loss=3.9381 val_loss=0.0000 scale=1.0000 norm=0.8325\n",
      "[iter 0] loss=4.0972 val_loss=0.0000 scale=0.5000 norm=0.4980\n",
      "[iter 100] loss=4.0390 val_loss=0.0000 scale=1.0000 norm=0.9339\n",
      "[iter 200] loss=4.0031 val_loss=0.0000 scale=1.0000 norm=0.8992\n",
      "[iter 300] loss=3.9731 val_loss=0.0000 scale=1.0000 norm=0.8710\n",
      "[iter 400] loss=3.9454 val_loss=0.0000 scale=1.0000 norm=0.8439\n",
      "[iter 0] loss=4.0836 val_loss=0.0000 scale=0.5000 norm=0.4918\n",
      "[iter 100] loss=4.0273 val_loss=0.0000 scale=1.0000 norm=0.9246\n",
      "[iter 200] loss=3.9947 val_loss=0.0000 scale=1.0000 norm=0.8925\n",
      "[iter 300] loss=3.9665 val_loss=0.0000 scale=1.0000 norm=0.8639\n",
      "[iter 400] loss=3.9403 val_loss=0.0000 scale=1.0000 norm=0.8385\n",
      "[iter 0] loss=4.0930 val_loss=0.0000 scale=0.5000 norm=0.4987\n",
      "[iter 100] loss=4.0320 val_loss=0.0000 scale=0.5000 norm=0.4672\n",
      "[iter 200] loss=3.9935 val_loss=0.0000 scale=1.0000 norm=0.8929\n",
      "[iter 300] loss=3.9641 val_loss=0.0000 scale=1.0000 norm=0.8629\n",
      "[iter 400] loss=3.9389 val_loss=0.0000 scale=1.0000 norm=0.8375\n",
      "[iter 0] loss=4.0924 val_loss=0.0000 scale=0.5000 norm=0.4949\n",
      "[iter 100] loss=4.0337 val_loss=0.0000 scale=0.5000 norm=0.4632\n",
      "[iter 200] loss=3.9965 val_loss=0.0000 scale=1.0000 norm=0.8882\n",
      "[iter 300] loss=3.9672 val_loss=0.0000 scale=1.0000 norm=0.8596\n",
      "[iter 400] loss=3.9407 val_loss=0.0000 scale=1.0000 norm=0.8336\n",
      "[iter 0] loss=4.0971 val_loss=0.0000 scale=0.5000 norm=0.4963\n",
      "[iter 100] loss=4.0360 val_loss=0.0000 scale=0.5000 norm=0.4644\n",
      "[iter 200] loss=3.9989 val_loss=0.0000 scale=1.0000 norm=0.8921\n",
      "[iter 300] loss=3.9679 val_loss=0.0000 scale=1.0000 norm=0.8627\n",
      "[iter 400] loss=3.9381 val_loss=0.0000 scale=1.0000 norm=0.8325\n",
      "[iter 0] loss=4.0972 val_loss=0.0000 scale=0.5000 norm=0.4980\n",
      "[iter 100] loss=4.0390 val_loss=0.0000 scale=1.0000 norm=0.9339\n",
      "[iter 200] loss=4.0031 val_loss=0.0000 scale=1.0000 norm=0.8992\n",
      "[iter 300] loss=3.9731 val_loss=0.0000 scale=1.0000 norm=0.8710\n",
      "[iter 400] loss=3.9454 val_loss=0.0000 scale=1.0000 norm=0.8439\n",
      "[iter 0] loss=4.0836 val_loss=0.0000 scale=0.5000 norm=0.4918\n",
      "[iter 100] loss=4.0273 val_loss=0.0000 scale=1.0000 norm=0.9246\n",
      "[iter 200] loss=3.9947 val_loss=0.0000 scale=1.0000 norm=0.8925\n",
      "[iter 300] loss=3.9665 val_loss=0.0000 scale=1.0000 norm=0.8639\n",
      "[iter 400] loss=3.9403 val_loss=0.0000 scale=1.0000 norm=0.8385\n",
      "[iter 0] loss=4.0930 val_loss=0.0000 scale=0.5000 norm=0.4987\n",
      "[iter 100] loss=4.0320 val_loss=0.0000 scale=0.5000 norm=0.4672\n",
      "[iter 200] loss=3.9935 val_loss=0.0000 scale=1.0000 norm=0.8929\n",
      "[iter 300] loss=3.9641 val_loss=0.0000 scale=1.0000 norm=0.8629\n",
      "[iter 400] loss=3.9389 val_loss=0.0000 scale=1.0000 norm=0.8375\n",
      "[iter 0] loss=4.0924 val_loss=0.0000 scale=0.5000 norm=0.4949\n",
      "[iter 100] loss=4.0337 val_loss=0.0000 scale=0.5000 norm=0.4632\n",
      "[iter 200] loss=3.9965 val_loss=0.0000 scale=1.0000 norm=0.8882\n",
      "[iter 300] loss=3.9672 val_loss=0.0000 scale=1.0000 norm=0.8596\n",
      "[iter 400] loss=3.9407 val_loss=0.0000 scale=1.0000 norm=0.8336\n",
      "[iter 0] loss=4.0971 val_loss=0.0000 scale=0.5000 norm=0.4963\n",
      "[iter 100] loss=4.0360 val_loss=0.0000 scale=0.5000 norm=0.4644\n",
      "[iter 200] loss=3.9989 val_loss=0.0000 scale=1.0000 norm=0.8921\n",
      "[iter 300] loss=3.9679 val_loss=0.0000 scale=1.0000 norm=0.8627\n",
      "[iter 400] loss=3.9381 val_loss=0.0000 scale=1.0000 norm=0.8325\n",
      "[iter 0] loss=4.0972 val_loss=0.0000 scale=0.5000 norm=0.4980\n",
      "[iter 100] loss=4.0390 val_loss=0.0000 scale=1.0000 norm=0.9339\n",
      "[iter 200] loss=4.0031 val_loss=0.0000 scale=1.0000 norm=0.8992\n",
      "[iter 300] loss=3.9731 val_loss=0.0000 scale=1.0000 norm=0.8710\n",
      "[iter 400] loss=3.9454 val_loss=0.0000 scale=1.0000 norm=0.8439\n",
      "[iter 0] loss=4.0836 val_loss=0.0000 scale=0.5000 norm=0.4918\n",
      "[iter 100] loss=4.0273 val_loss=0.0000 scale=1.0000 norm=0.9246\n",
      "[iter 200] loss=3.9947 val_loss=0.0000 scale=1.0000 norm=0.8925\n",
      "[iter 300] loss=3.9665 val_loss=0.0000 scale=1.0000 norm=0.8639\n",
      "[iter 400] loss=3.9403 val_loss=0.0000 scale=1.0000 norm=0.8385\n",
      "[iter 0] loss=4.0930 val_loss=0.0000 scale=0.5000 norm=0.4987\n",
      "[iter 100] loss=4.0320 val_loss=0.0000 scale=0.5000 norm=0.4672\n",
      "[iter 200] loss=3.9935 val_loss=0.0000 scale=1.0000 norm=0.8929\n",
      "[iter 300] loss=3.9641 val_loss=0.0000 scale=1.0000 norm=0.8629\n",
      "[iter 400] loss=3.9389 val_loss=0.0000 scale=1.0000 norm=0.8375\n",
      "[iter 0] loss=4.0924 val_loss=0.0000 scale=0.5000 norm=0.4949\n",
      "[iter 100] loss=4.0337 val_loss=0.0000 scale=0.5000 norm=0.4632\n",
      "[iter 200] loss=3.9965 val_loss=0.0000 scale=1.0000 norm=0.8882\n",
      "[iter 300] loss=3.9672 val_loss=0.0000 scale=1.0000 norm=0.8596\n",
      "[iter 400] loss=3.9407 val_loss=0.0000 scale=1.0000 norm=0.8336\n",
      "[iter 0] loss=4.0953 val_loss=0.0000 scale=1.0000 norm=11.6644\n",
      "[iter 100] loss=4.0508 val_loss=0.0000 scale=1.0000 norm=11.1425\n",
      "[iter 200] loss=3.9966 val_loss=0.0000 scale=1.0000 norm=10.6151\n",
      "[iter 300] loss=3.9294 val_loss=0.0000 scale=1.0000 norm=9.8811\n",
      "[iter 400] loss=3.9567 val_loss=0.0000 scale=1.0000 norm=10.2116\n",
      "[iter 0] loss=4.1019 val_loss=0.0000 scale=1.0000 norm=11.7933\n",
      "[iter 100] loss=4.0373 val_loss=0.0000 scale=1.0000 norm=11.0106\n",
      "[iter 200] loss=4.0052 val_loss=0.0000 scale=1.0000 norm=10.7307\n",
      "[iter 300] loss=3.9663 val_loss=0.0000 scale=2.0000 norm=20.5943\n",
      "[iter 400] loss=3.9506 val_loss=0.0000 scale=1.0000 norm=10.2110\n",
      "[iter 0] loss=4.1117 val_loss=0.0000 scale=1.0000 norm=12.0439\n",
      "[iter 100] loss=4.0158 val_loss=0.0000 scale=1.0000 norm=10.8435\n",
      "[iter 200] loss=3.9926 val_loss=0.0000 scale=1.0000 norm=10.5818\n",
      "[iter 300] loss=3.9350 val_loss=0.0000 scale=1.0000 norm=9.9531\n",
      "[iter 400] loss=3.9504 val_loss=0.0000 scale=1.0000 norm=10.2527\n",
      "[iter 0] loss=4.1104 val_loss=0.0000 scale=1.0000 norm=11.9046\n",
      "[iter 100] loss=4.0378 val_loss=0.0000 scale=1.0000 norm=11.0700\n",
      "[iter 200] loss=3.9947 val_loss=0.0000 scale=1.0000 norm=10.5534\n",
      "[iter 300] loss=3.9510 val_loss=0.0000 scale=1.0000 norm=10.1464\n",
      "[iter 400] loss=3.9442 val_loss=0.0000 scale=1.0000 norm=10.0797\n",
      "[iter 0] loss=4.1027 val_loss=0.0000 scale=1.0000 norm=11.7968\n",
      "[iter 100] loss=4.0410 val_loss=0.0000 scale=1.0000 norm=11.0959\n",
      "[iter 200] loss=3.9873 val_loss=0.0000 scale=1.0000 norm=10.4504\n",
      "[iter 300] loss=3.9791 val_loss=0.0000 scale=1.0000 norm=10.4710\n",
      "[iter 400] loss=3.9521 val_loss=0.0000 scale=1.0000 norm=10.2297\n",
      "[iter 0] loss=4.0953 val_loss=0.0000 scale=1.0000 norm=11.6644\n",
      "[iter 100] loss=4.0506 val_loss=0.0000 scale=1.0000 norm=11.1425\n",
      "[iter 200] loss=3.9964 val_loss=0.0000 scale=1.0000 norm=10.6166\n",
      "[iter 300] loss=3.9296 val_loss=0.0000 scale=1.0000 norm=9.8822\n",
      "[iter 400] loss=3.9569 val_loss=0.0000 scale=1.0000 norm=10.2149\n",
      "[iter 0] loss=4.1019 val_loss=0.0000 scale=1.0000 norm=11.7933\n",
      "[iter 100] loss=4.0375 val_loss=0.0000 scale=1.0000 norm=11.0106\n",
      "[iter 200] loss=4.0054 val_loss=0.0000 scale=1.0000 norm=10.7305\n",
      "[iter 300] loss=3.9666 val_loss=0.0000 scale=2.0000 norm=20.5995\n",
      "[iter 400] loss=3.9509 val_loss=0.0000 scale=1.0000 norm=10.2137\n",
      "[iter 0] loss=4.1117 val_loss=0.0000 scale=1.0000 norm=12.0439\n",
      "[iter 100] loss=4.0158 val_loss=0.0000 scale=1.0000 norm=10.8435\n",
      "[iter 200] loss=3.9923 val_loss=0.0000 scale=1.0000 norm=10.5818\n",
      "[iter 300] loss=3.9352 val_loss=0.0000 scale=1.0000 norm=9.9512\n",
      "[iter 400] loss=3.9499 val_loss=0.0000 scale=1.0000 norm=10.2456\n",
      "[iter 0] loss=4.1104 val_loss=0.0000 scale=1.0000 norm=11.9046\n",
      "[iter 100] loss=4.0378 val_loss=0.0000 scale=1.0000 norm=11.0700\n",
      "[iter 200] loss=3.9949 val_loss=0.0000 scale=1.0000 norm=10.5535\n",
      "[iter 300] loss=3.9508 val_loss=0.0000 scale=1.0000 norm=10.1455\n",
      "[iter 400] loss=3.9443 val_loss=0.0000 scale=1.0000 norm=10.0810\n",
      "[iter 0] loss=4.1027 val_loss=0.0000 scale=1.0000 norm=11.7968\n",
      "[iter 100] loss=4.0415 val_loss=0.0000 scale=1.0000 norm=11.1011\n",
      "[iter 200] loss=3.9875 val_loss=0.0000 scale=1.0000 norm=10.4526\n",
      "[iter 300] loss=3.9794 val_loss=0.0000 scale=1.0000 norm=10.4739\n",
      "[iter 400] loss=3.9516 val_loss=0.0000 scale=1.0000 norm=10.2250\n",
      "[iter 0] loss=4.0953 val_loss=0.0000 scale=1.0000 norm=11.6644\n",
      "[iter 100] loss=4.0506 val_loss=0.0000 scale=1.0000 norm=11.1425\n",
      "[iter 200] loss=3.9962 val_loss=0.0000 scale=1.0000 norm=10.6166\n",
      "[iter 300] loss=3.9295 val_loss=0.0000 scale=1.0000 norm=9.8824\n",
      "[iter 400] loss=3.9569 val_loss=0.0000 scale=1.0000 norm=10.2144\n",
      "[iter 0] loss=4.1019 val_loss=0.0000 scale=1.0000 norm=11.7933\n",
      "[iter 100] loss=4.0375 val_loss=0.0000 scale=1.0000 norm=11.0106\n",
      "[iter 200] loss=4.0055 val_loss=0.0000 scale=1.0000 norm=10.7317\n",
      "[iter 300] loss=3.9667 val_loss=0.0000 scale=2.0000 norm=20.6036\n",
      "[iter 400] loss=3.9517 val_loss=0.0000 scale=1.0000 norm=10.2131\n",
      "[iter 0] loss=4.1117 val_loss=0.0000 scale=1.0000 norm=12.0439\n",
      "[iter 100] loss=4.0158 val_loss=0.0000 scale=1.0000 norm=10.8435\n",
      "[iter 200] loss=3.9926 val_loss=0.0000 scale=1.0000 norm=10.5846\n",
      "[iter 300] loss=3.9355 val_loss=0.0000 scale=1.0000 norm=9.9539\n",
      "[iter 400] loss=3.9508 val_loss=0.0000 scale=1.0000 norm=10.2549\n",
      "[iter 0] loss=4.1104 val_loss=0.0000 scale=1.0000 norm=11.9046\n",
      "[iter 100] loss=4.0377 val_loss=0.0000 scale=1.0000 norm=11.0700\n",
      "[iter 200] loss=3.9943 val_loss=0.0000 scale=1.0000 norm=10.5515\n",
      "[iter 300] loss=3.9502 val_loss=0.0000 scale=1.0000 norm=10.1466\n",
      "[iter 400] loss=3.9437 val_loss=0.0000 scale=1.0000 norm=10.0781\n",
      "[iter 0] loss=4.1027 val_loss=0.0000 scale=1.0000 norm=11.7968\n",
      "[iter 100] loss=4.0411 val_loss=0.0000 scale=1.0000 norm=11.1011\n",
      "[iter 200] loss=3.9873 val_loss=0.0000 scale=1.0000 norm=10.4529\n",
      "[iter 300] loss=3.9791 val_loss=0.0000 scale=1.0000 norm=10.4706\n",
      "[iter 400] loss=3.9516 val_loss=0.0000 scale=1.0000 norm=10.2239\n",
      "[iter 0] loss=4.0953 val_loss=0.0000 scale=0.5000 norm=0.4916\n",
      "[iter 100] loss=4.1034 val_loss=0.0000 scale=0.5000 norm=0.5015\n",
      "[iter 200] loss=4.0827 val_loss=0.0000 scale=0.5000 norm=0.4814\n",
      "[iter 300] loss=4.0384 val_loss=0.0000 scale=1.0000 norm=0.9117\n",
      "[iter 400] loss=4.0739 val_loss=0.0000 scale=0.5000 norm=0.4781\n",
      "[iter 0] loss=4.1019 val_loss=0.0000 scale=0.5000 norm=0.4898\n",
      "[iter 100] loss=4.0900 val_loss=0.0000 scale=0.5000 norm=0.4928\n",
      "[iter 200] loss=4.0801 val_loss=0.0000 scale=0.5000 norm=0.4804\n",
      "[iter 300] loss=4.0674 val_loss=0.0000 scale=1.0000 norm=0.9531\n",
      "[iter 400] loss=4.0697 val_loss=0.0000 scale=0.5000 norm=0.4831\n",
      "[iter 0] loss=4.1117 val_loss=0.0000 scale=0.5000 norm=0.4894\n",
      "[iter 100] loss=4.0629 val_loss=0.0000 scale=0.5000 norm=0.4753\n",
      "[iter 200] loss=4.0620 val_loss=0.0000 scale=0.5000 norm=0.4708\n",
      "[iter 300] loss=4.0296 val_loss=0.0000 scale=0.5000 norm=0.4573\n",
      "[iter 400] loss=4.0683 val_loss=0.0000 scale=0.5000 norm=0.4807\n",
      "[iter 0] loss=4.1104 val_loss=0.0000 scale=0.5000 norm=0.4918\n",
      "[iter 100] loss=4.0824 val_loss=0.0000 scale=0.5000 norm=0.4851\n",
      "[iter 200] loss=4.0655 val_loss=0.0000 scale=0.5000 norm=0.4807\n",
      "[iter 300] loss=4.0411 val_loss=0.0000 scale=0.5000 norm=0.4589\n",
      "[iter 400] loss=4.0564 val_loss=0.0000 scale=0.5000 norm=0.4816\n",
      "[iter 0] loss=4.1027 val_loss=0.0000 scale=0.5000 norm=0.4908\n",
      "[iter 100] loss=4.0947 val_loss=0.0000 scale=0.5000 norm=0.4883\n",
      "[iter 200] loss=4.0662 val_loss=0.0000 scale=0.5000 norm=0.4812\n",
      "[iter 300] loss=4.0739 val_loss=0.0000 scale=0.5000 norm=0.4788\n",
      "[iter 400] loss=4.0681 val_loss=0.0000 scale=0.5000 norm=0.4782\n",
      "[iter 0] loss=4.0953 val_loss=0.0000 scale=0.5000 norm=0.4916\n",
      "[iter 100] loss=4.1035 val_loss=0.0000 scale=0.5000 norm=0.5019\n",
      "[iter 200] loss=4.0830 val_loss=0.0000 scale=0.5000 norm=0.4818\n",
      "[iter 300] loss=4.0387 val_loss=0.0000 scale=1.0000 norm=0.9117\n",
      "[iter 400] loss=4.0739 val_loss=0.0000 scale=0.5000 norm=0.4776\n",
      "[iter 0] loss=4.1019 val_loss=0.0000 scale=0.5000 norm=0.4898\n",
      "[iter 100] loss=4.0901 val_loss=0.0000 scale=0.5000 norm=0.4928\n",
      "[iter 200] loss=4.0798 val_loss=0.0000 scale=0.5000 norm=0.4798\n",
      "[iter 300] loss=4.0670 val_loss=0.0000 scale=1.0000 norm=0.9527\n",
      "[iter 400] loss=4.0692 val_loss=0.0000 scale=0.5000 norm=0.4831\n",
      "[iter 0] loss=4.1117 val_loss=0.0000 scale=0.5000 norm=0.4894\n",
      "[iter 100] loss=4.0630 val_loss=0.0000 scale=0.5000 norm=0.4754\n",
      "[iter 200] loss=4.0619 val_loss=0.0000 scale=0.5000 norm=0.4706\n",
      "[iter 300] loss=4.0293 val_loss=0.0000 scale=0.5000 norm=0.4569\n",
      "[iter 400] loss=4.0682 val_loss=0.0000 scale=0.5000 norm=0.4809\n",
      "[iter 0] loss=4.1104 val_loss=0.0000 scale=0.5000 norm=0.4918\n",
      "[iter 100] loss=4.0829 val_loss=0.0000 scale=0.5000 norm=0.4856\n",
      "[iter 200] loss=4.0655 val_loss=0.0000 scale=0.5000 norm=0.4807\n",
      "[iter 300] loss=4.0408 val_loss=0.0000 scale=0.5000 norm=0.4590\n",
      "[iter 400] loss=4.0569 val_loss=0.0000 scale=1.0000 norm=0.9638\n",
      "[iter 0] loss=4.1027 val_loss=0.0000 scale=0.5000 norm=0.4908\n",
      "[iter 100] loss=4.0947 val_loss=0.0000 scale=0.5000 norm=0.4883\n",
      "[iter 200] loss=4.0662 val_loss=0.0000 scale=0.5000 norm=0.4812\n",
      "[iter 300] loss=4.0736 val_loss=0.0000 scale=0.5000 norm=0.4783\n",
      "[iter 400] loss=4.0683 val_loss=0.0000 scale=0.5000 norm=0.4786\n",
      "[iter 0] loss=4.0953 val_loss=0.0000 scale=0.5000 norm=0.4916\n",
      "[iter 100] loss=4.1035 val_loss=0.0000 scale=0.5000 norm=0.5019\n",
      "[iter 200] loss=4.0826 val_loss=0.0000 scale=0.5000 norm=0.4815\n",
      "[iter 300] loss=4.0389 val_loss=0.0000 scale=1.0000 norm=0.9125\n",
      "[iter 400] loss=4.0746 val_loss=0.0000 scale=0.5000 norm=0.4784\n",
      "[iter 0] loss=4.1019 val_loss=0.0000 scale=0.5000 norm=0.4898\n",
      "[iter 100] loss=4.0899 val_loss=0.0000 scale=0.5000 norm=0.4925\n",
      "[iter 200] loss=4.0799 val_loss=0.0000 scale=0.5000 norm=0.4799\n",
      "[iter 300] loss=4.0666 val_loss=0.0000 scale=1.0000 norm=0.9516\n",
      "[iter 400] loss=4.0694 val_loss=0.0000 scale=0.5000 norm=0.4829\n",
      "[iter 0] loss=4.1117 val_loss=0.0000 scale=0.5000 norm=0.4894\n",
      "[iter 100] loss=4.0631 val_loss=0.0000 scale=0.5000 norm=0.4754\n",
      "[iter 200] loss=4.0619 val_loss=0.0000 scale=0.5000 norm=0.4705\n",
      "[iter 300] loss=4.0298 val_loss=0.0000 scale=0.5000 norm=0.4570\n",
      "[iter 400] loss=4.0680 val_loss=0.0000 scale=0.5000 norm=0.4802\n",
      "[iter 0] loss=4.1104 val_loss=0.0000 scale=0.5000 norm=0.4918\n",
      "[iter 100] loss=4.0826 val_loss=0.0000 scale=0.5000 norm=0.4854\n",
      "[iter 200] loss=4.0655 val_loss=0.0000 scale=0.5000 norm=0.4809\n",
      "[iter 300] loss=4.0410 val_loss=0.0000 scale=0.5000 norm=0.4590\n",
      "[iter 400] loss=4.0568 val_loss=0.0000 scale=0.5000 norm=0.4820\n",
      "[iter 0] loss=4.1027 val_loss=0.0000 scale=0.5000 norm=0.4908\n",
      "[iter 100] loss=4.0950 val_loss=0.0000 scale=0.5000 norm=0.4885\n",
      "[iter 200] loss=4.0661 val_loss=0.0000 scale=0.5000 norm=0.4808\n",
      "[iter 300] loss=4.0739 val_loss=0.0000 scale=0.5000 norm=0.4781\n",
      "[iter 400] loss=4.0688 val_loss=0.0000 scale=0.5000 norm=0.4790\n",
      "[iter 0] loss=4.0887 val_loss=0.0000 scale=1.0000 norm=11.5815\n",
      "[iter 100] loss=4.0370 val_loss=0.0000 scale=1.0000 norm=10.9016\n",
      "[iter 200] loss=4.0055 val_loss=0.0000 scale=1.0000 norm=10.6516\n",
      "[iter 300] loss=3.9608 val_loss=0.0000 scale=1.0000 norm=10.1961\n",
      "[iter 400] loss=3.9603 val_loss=0.0000 scale=1.0000 norm=10.2922\n",
      "[iter 0] loss=4.1079 val_loss=0.0000 scale=1.0000 norm=11.7758\n",
      "[iter 100] loss=4.0352 val_loss=0.0000 scale=1.0000 norm=10.9594\n",
      "[iter 200] loss=4.0000 val_loss=0.0000 scale=1.0000 norm=10.6139\n",
      "[iter 300] loss=3.9722 val_loss=0.0000 scale=1.0000 norm=10.3824\n",
      "[iter 400] loss=3.9597 val_loss=0.0000 scale=1.0000 norm=10.2779\n",
      "[iter 0] loss=4.1036 val_loss=0.0000 scale=1.0000 norm=11.8357\n",
      "[iter 100] loss=4.0225 val_loss=0.0000 scale=1.0000 norm=10.8848\n",
      "[iter 200] loss=3.9891 val_loss=0.0000 scale=1.0000 norm=10.5391\n",
      "[iter 300] loss=3.9451 val_loss=0.0000 scale=1.0000 norm=10.1469\n",
      "[iter 400] loss=3.9528 val_loss=0.0000 scale=1.0000 norm=10.2879\n",
      "[iter 0] loss=4.1035 val_loss=0.0000 scale=1.0000 norm=11.7229\n",
      "[iter 100] loss=4.0333 val_loss=0.0000 scale=1.0000 norm=10.9932\n",
      "[iter 200] loss=3.9939 val_loss=0.0000 scale=1.0000 norm=10.5067\n",
      "[iter 300] loss=3.9576 val_loss=0.0000 scale=1.0000 norm=10.2424\n",
      "[iter 400] loss=3.9577 val_loss=0.0000 scale=1.0000 norm=10.2564\n",
      "[iter 0] loss=4.1023 val_loss=0.0000 scale=1.0000 norm=11.7478\n",
      "[iter 100] loss=4.0346 val_loss=0.0000 scale=1.0000 norm=11.0233\n",
      "[iter 200] loss=3.9817 val_loss=0.0000 scale=1.0000 norm=10.3557\n",
      "[iter 300] loss=3.9672 val_loss=0.0000 scale=1.0000 norm=10.3373\n",
      "[iter 400] loss=3.9619 val_loss=0.0000 scale=1.0000 norm=10.3380\n",
      "[iter 0] loss=4.0887 val_loss=0.0000 scale=1.0000 norm=11.5815\n",
      "[iter 100] loss=4.0368 val_loss=0.0000 scale=1.0000 norm=10.9015\n",
      "[iter 200] loss=4.0058 val_loss=0.0000 scale=1.0000 norm=10.6541\n",
      "[iter 300] loss=3.9614 val_loss=0.0000 scale=1.0000 norm=10.2030\n",
      "[iter 400] loss=3.9605 val_loss=0.0000 scale=1.0000 norm=10.2962\n",
      "[iter 0] loss=4.1079 val_loss=0.0000 scale=1.0000 norm=11.7758\n",
      "[iter 100] loss=4.0352 val_loss=0.0000 scale=1.0000 norm=10.9594\n",
      "[iter 200] loss=3.9998 val_loss=0.0000 scale=1.0000 norm=10.6139\n",
      "[iter 300] loss=3.9724 val_loss=0.0000 scale=1.0000 norm=10.3824\n",
      "[iter 400] loss=3.9599 val_loss=0.0000 scale=1.0000 norm=10.2779\n",
      "[iter 0] loss=4.1036 val_loss=0.0000 scale=1.0000 norm=11.8357\n",
      "[iter 100] loss=4.0224 val_loss=0.0000 scale=1.0000 norm=10.8848\n",
      "[iter 200] loss=3.9893 val_loss=0.0000 scale=1.0000 norm=10.5391\n",
      "[iter 300] loss=3.9450 val_loss=0.0000 scale=1.0000 norm=10.1469\n",
      "[iter 400] loss=3.9521 val_loss=0.0000 scale=1.0000 norm=10.2814\n",
      "[iter 0] loss=4.1035 val_loss=0.0000 scale=1.0000 norm=11.7229\n",
      "[iter 100] loss=4.0330 val_loss=0.0000 scale=1.0000 norm=10.9931\n",
      "[iter 200] loss=3.9935 val_loss=0.0000 scale=1.0000 norm=10.5006\n",
      "[iter 300] loss=3.9573 val_loss=0.0000 scale=1.0000 norm=10.2363\n",
      "[iter 400] loss=3.9575 val_loss=0.0000 scale=1.0000 norm=10.2530\n",
      "[iter 0] loss=4.1023 val_loss=0.0000 scale=1.0000 norm=11.7478\n",
      "[iter 100] loss=4.0345 val_loss=0.0000 scale=1.0000 norm=11.0233\n",
      "[iter 200] loss=3.9817 val_loss=0.0000 scale=1.0000 norm=10.3559\n",
      "[iter 300] loss=3.9672 val_loss=0.0000 scale=1.0000 norm=10.3377\n",
      "[iter 400] loss=3.9618 val_loss=0.0000 scale=1.0000 norm=10.3381\n",
      "[iter 0] loss=4.0887 val_loss=0.0000 scale=1.0000 norm=11.5815\n",
      "[iter 100] loss=4.0371 val_loss=0.0000 scale=1.0000 norm=10.9016\n",
      "[iter 200] loss=4.0056 val_loss=0.0000 scale=1.0000 norm=10.6516\n",
      "[iter 300] loss=3.9608 val_loss=0.0000 scale=1.0000 norm=10.1974\n",
      "[iter 400] loss=3.9600 val_loss=0.0000 scale=1.0000 norm=10.2946\n",
      "[iter 0] loss=4.1079 val_loss=0.0000 scale=1.0000 norm=11.7758\n",
      "[iter 100] loss=4.0351 val_loss=0.0000 scale=1.0000 norm=10.9594\n",
      "[iter 200] loss=3.9999 val_loss=0.0000 scale=1.0000 norm=10.6139\n",
      "[iter 300] loss=3.9723 val_loss=0.0000 scale=1.0000 norm=10.3844\n",
      "[iter 400] loss=3.9600 val_loss=0.0000 scale=1.0000 norm=10.2800\n",
      "[iter 0] loss=4.1036 val_loss=0.0000 scale=1.0000 norm=11.8357\n",
      "[iter 100] loss=4.0224 val_loss=0.0000 scale=1.0000 norm=10.8848\n",
      "[iter 200] loss=3.9893 val_loss=0.0000 scale=1.0000 norm=10.5391\n",
      "[iter 300] loss=3.9450 val_loss=0.0000 scale=1.0000 norm=10.1469\n",
      "[iter 400] loss=3.9529 val_loss=0.0000 scale=1.0000 norm=10.2899\n",
      "[iter 0] loss=4.1035 val_loss=0.0000 scale=1.0000 norm=11.7229\n",
      "[iter 100] loss=4.0331 val_loss=0.0000 scale=1.0000 norm=10.9931\n",
      "[iter 200] loss=3.9935 val_loss=0.0000 scale=1.0000 norm=10.5043\n",
      "[iter 300] loss=3.9573 val_loss=0.0000 scale=1.0000 norm=10.2404\n",
      "[iter 400] loss=3.9573 val_loss=0.0000 scale=1.0000 norm=10.2548\n",
      "[iter 0] loss=4.1023 val_loss=0.0000 scale=1.0000 norm=11.7478\n",
      "[iter 100] loss=4.0345 val_loss=0.0000 scale=1.0000 norm=11.0233\n",
      "[iter 200] loss=3.9815 val_loss=0.0000 scale=1.0000 norm=10.3557\n",
      "[iter 300] loss=3.9670 val_loss=0.0000 scale=1.0000 norm=10.3375\n",
      "[iter 400] loss=3.9621 val_loss=0.0000 scale=1.0000 norm=10.3383\n",
      "[iter 0] loss=4.0887 val_loss=0.0000 scale=0.5000 norm=0.4880\n",
      "[iter 100] loss=4.0905 val_loss=0.0000 scale=0.5000 norm=0.4975\n",
      "[iter 200] loss=4.0879 val_loss=0.0000 scale=0.5000 norm=0.4922\n",
      "[iter 300] loss=4.0566 val_loss=0.0000 scale=1.0000 norm=0.9449\n",
      "[iter 400] loss=4.0742 val_loss=0.0000 scale=1.0000 norm=0.9598\n",
      "[iter 0] loss=4.1079 val_loss=0.0000 scale=0.5000 norm=0.5021\n",
      "[iter 100] loss=4.0872 val_loss=0.0000 scale=0.5000 norm=0.4910\n",
      "[iter 200] loss=4.0762 val_loss=0.0000 scale=0.5000 norm=0.4799\n",
      "[iter 300] loss=4.0696 val_loss=0.0000 scale=1.0000 norm=0.9621\n",
      "[iter 400] loss=4.0718 val_loss=0.0000 scale=0.5000 norm=0.4830\n",
      "[iter 0] loss=4.1036 val_loss=0.0000 scale=0.5000 norm=0.4960\n",
      "[iter 100] loss=4.0690 val_loss=0.0000 scale=0.5000 norm=0.4799\n",
      "[iter 200] loss=4.0611 val_loss=0.0000 scale=0.5000 norm=0.4738\n",
      "[iter 300] loss=4.0367 val_loss=0.0000 scale=0.5000 norm=0.4623\n",
      "[iter 400] loss=4.0634 val_loss=0.0000 scale=0.5000 norm=0.4760\n",
      "[iter 0] loss=4.1035 val_loss=0.0000 scale=0.5000 norm=0.4996\n",
      "[iter 100] loss=4.0783 val_loss=0.0000 scale=0.5000 norm=0.4838\n",
      "[iter 200] loss=4.0669 val_loss=0.0000 scale=1.0000 norm=0.9689\n",
      "[iter 300] loss=4.0486 val_loss=0.0000 scale=0.5000 norm=0.4701\n",
      "[iter 400] loss=4.0632 val_loss=0.0000 scale=0.5000 norm=0.4818\n",
      "[iter 0] loss=4.1023 val_loss=0.0000 scale=0.5000 norm=0.4949\n",
      "[iter 100] loss=4.0850 val_loss=0.0000 scale=0.5000 norm=0.4829\n",
      "[iter 200] loss=4.0612 val_loss=0.0000 scale=0.5000 norm=0.4809\n",
      "[iter 300] loss=4.0601 val_loss=0.0000 scale=1.0000 norm=0.9507\n",
      "[iter 400] loss=4.0689 val_loss=0.0000 scale=0.5000 norm=0.4758\n",
      "[iter 0] loss=4.0887 val_loss=0.0000 scale=0.5000 norm=0.4880\n",
      "[iter 100] loss=4.0905 val_loss=0.0000 scale=0.5000 norm=0.4973\n",
      "[iter 200] loss=4.0879 val_loss=0.0000 scale=0.5000 norm=0.4921\n",
      "[iter 300] loss=4.0563 val_loss=0.0000 scale=1.0000 norm=0.9441\n",
      "[iter 400] loss=4.0742 val_loss=0.0000 scale=1.0000 norm=0.9600\n",
      "[iter 0] loss=4.1079 val_loss=0.0000 scale=0.5000 norm=0.5021\n",
      "[iter 100] loss=4.0873 val_loss=0.0000 scale=0.5000 norm=0.4911\n",
      "[iter 200] loss=4.0759 val_loss=0.0000 scale=0.5000 norm=0.4795\n",
      "[iter 300] loss=4.0693 val_loss=0.0000 scale=1.0000 norm=0.9611\n",
      "[iter 400] loss=4.0713 val_loss=0.0000 scale=0.5000 norm=0.4824\n",
      "[iter 0] loss=4.1036 val_loss=0.0000 scale=0.5000 norm=0.4960\n",
      "[iter 100] loss=4.0692 val_loss=0.0000 scale=0.5000 norm=0.4802\n",
      "[iter 200] loss=4.0611 val_loss=0.0000 scale=0.5000 norm=0.4737\n",
      "[iter 300] loss=4.0368 val_loss=0.0000 scale=0.5000 norm=0.4622\n",
      "[iter 400] loss=4.0639 val_loss=0.0000 scale=0.5000 norm=0.4764\n",
      "[iter 0] loss=4.1035 val_loss=0.0000 scale=0.5000 norm=0.4996\n",
      "[iter 100] loss=4.0780 val_loss=0.0000 scale=0.5000 norm=0.4836\n",
      "[iter 200] loss=4.0669 val_loss=0.0000 scale=0.5000 norm=0.4846\n",
      "[iter 300] loss=4.0488 val_loss=0.0000 scale=0.5000 norm=0.4704\n",
      "[iter 400] loss=4.0634 val_loss=0.0000 scale=0.5000 norm=0.4819\n",
      "[iter 0] loss=4.1023 val_loss=0.0000 scale=0.5000 norm=0.4949\n",
      "[iter 100] loss=4.0851 val_loss=0.0000 scale=0.5000 norm=0.4830\n",
      "[iter 200] loss=4.0611 val_loss=0.0000 scale=0.5000 norm=0.4808\n",
      "[iter 300] loss=4.0601 val_loss=0.0000 scale=1.0000 norm=0.9506\n",
      "[iter 400] loss=4.0691 val_loss=0.0000 scale=0.5000 norm=0.4759\n",
      "[iter 0] loss=4.0887 val_loss=0.0000 scale=0.5000 norm=0.4880\n",
      "[iter 100] loss=4.0901 val_loss=0.0000 scale=0.5000 norm=0.4971\n",
      "[iter 200] loss=4.0878 val_loss=0.0000 scale=0.5000 norm=0.4922\n",
      "[iter 300] loss=4.0562 val_loss=0.0000 scale=1.0000 norm=0.9438\n",
      "[iter 400] loss=4.0741 val_loss=0.0000 scale=1.0000 norm=0.9600\n",
      "[iter 0] loss=4.1079 val_loss=0.0000 scale=0.5000 norm=0.5021\n",
      "[iter 100] loss=4.0873 val_loss=0.0000 scale=0.5000 norm=0.4911\n",
      "[iter 200] loss=4.0760 val_loss=0.0000 scale=0.5000 norm=0.4797\n",
      "[iter 300] loss=4.0696 val_loss=0.0000 scale=1.0000 norm=0.9623\n",
      "[iter 400] loss=4.0715 val_loss=0.0000 scale=0.5000 norm=0.4824\n",
      "[iter 0] loss=4.1036 val_loss=0.0000 scale=0.5000 norm=0.4960\n",
      "[iter 100] loss=4.0689 val_loss=0.0000 scale=0.5000 norm=0.4798\n",
      "[iter 200] loss=4.0610 val_loss=0.0000 scale=0.5000 norm=0.4736\n",
      "[iter 300] loss=4.0367 val_loss=0.0000 scale=0.5000 norm=0.4624\n",
      "[iter 400] loss=4.0637 val_loss=0.0000 scale=0.5000 norm=0.4764\n",
      "[iter 0] loss=4.1035 val_loss=0.0000 scale=0.5000 norm=0.4996\n",
      "[iter 100] loss=4.0781 val_loss=0.0000 scale=0.5000 norm=0.4836\n",
      "[iter 200] loss=4.0669 val_loss=0.0000 scale=1.0000 norm=0.9692\n",
      "[iter 300] loss=4.0489 val_loss=0.0000 scale=0.5000 norm=0.4702\n",
      "[iter 400] loss=4.0633 val_loss=0.0000 scale=0.5000 norm=0.4816\n",
      "[iter 0] loss=4.1023 val_loss=0.0000 scale=0.5000 norm=0.4949\n",
      "[iter 100] loss=4.0851 val_loss=0.0000 scale=0.5000 norm=0.4830\n",
      "[iter 200] loss=4.0614 val_loss=0.0000 scale=0.5000 norm=0.4810\n",
      "[iter 300] loss=4.0605 val_loss=0.0000 scale=1.0000 norm=0.9513\n",
      "[iter 400] loss=4.0690 val_loss=0.0000 scale=0.5000 norm=0.4757\n",
      "[iter 0] loss=4.0971 val_loss=0.0000 scale=1.0000 norm=11.6012\n",
      "[iter 100] loss=4.0331 val_loss=0.0000 scale=1.0000 norm=10.9091\n",
      "[iter 200] loss=4.0003 val_loss=0.0000 scale=1.0000 norm=10.5789\n",
      "[iter 300] loss=3.9770 val_loss=0.0000 scale=1.0000 norm=10.3604\n",
      "[iter 400] loss=3.9580 val_loss=0.0000 scale=1.0000 norm=10.1938\n",
      "[iter 0] loss=4.0972 val_loss=0.0000 scale=1.0000 norm=11.6172\n",
      "[iter 100] loss=4.0388 val_loss=0.0000 scale=1.0000 norm=10.9741\n",
      "[iter 200] loss=4.0072 val_loss=0.0000 scale=1.0000 norm=10.6531\n",
      "[iter 300] loss=3.9850 val_loss=0.0000 scale=1.0000 norm=10.4395\n",
      "[iter 400] loss=3.9665 val_loss=0.0000 scale=1.0000 norm=10.2700\n",
      "[iter 0] loss=4.0836 val_loss=0.0000 scale=1.0000 norm=11.5145\n",
      "[iter 100] loss=4.0281 val_loss=0.0000 scale=1.0000 norm=10.9305\n",
      "[iter 200] loss=3.9964 val_loss=0.0000 scale=1.0000 norm=10.6064\n",
      "[iter 300] loss=3.9738 val_loss=0.0000 scale=1.0000 norm=10.3869\n",
      "[iter 400] loss=3.9550 val_loss=0.0000 scale=1.0000 norm=10.2210\n",
      "[iter 0] loss=4.0930 val_loss=0.0000 scale=1.0000 norm=11.5486\n",
      "[iter 100] loss=4.0365 val_loss=0.0000 scale=1.0000 norm=10.9639\n",
      "[iter 200] loss=4.0049 val_loss=0.0000 scale=1.0000 norm=10.6484\n",
      "[iter 300] loss=3.9825 val_loss=0.0000 scale=1.0000 norm=10.4365\n",
      "[iter 400] loss=3.9644 val_loss=0.0000 scale=1.0000 norm=10.2755\n",
      "[iter 0] loss=4.0924 val_loss=0.0000 scale=1.0000 norm=11.5740\n",
      "[iter 100] loss=4.0341 val_loss=0.0000 scale=1.0000 norm=10.9649\n",
      "[iter 200] loss=4.0016 val_loss=0.0000 scale=1.0000 norm=10.6503\n",
      "[iter 300] loss=3.9797 val_loss=0.0000 scale=1.0000 norm=10.4442\n",
      "[iter 400] loss=3.9619 val_loss=0.0000 scale=1.0000 norm=10.2827\n",
      "[iter 0] loss=4.0971 val_loss=0.0000 scale=1.0000 norm=11.6012\n",
      "[iter 100] loss=4.0331 val_loss=0.0000 scale=1.0000 norm=10.9091\n",
      "[iter 200] loss=4.0003 val_loss=0.0000 scale=1.0000 norm=10.5789\n",
      "[iter 300] loss=3.9770 val_loss=0.0000 scale=1.0000 norm=10.3604\n",
      "[iter 400] loss=3.9580 val_loss=0.0000 scale=1.0000 norm=10.1938\n",
      "[iter 0] loss=4.0972 val_loss=0.0000 scale=1.0000 norm=11.6172\n",
      "[iter 100] loss=4.0388 val_loss=0.0000 scale=1.0000 norm=10.9741\n",
      "[iter 200] loss=4.0072 val_loss=0.0000 scale=1.0000 norm=10.6531\n",
      "[iter 300] loss=3.9850 val_loss=0.0000 scale=1.0000 norm=10.4395\n",
      "[iter 400] loss=3.9665 val_loss=0.0000 scale=1.0000 norm=10.2700\n",
      "[iter 0] loss=4.0836 val_loss=0.0000 scale=1.0000 norm=11.5145\n",
      "[iter 100] loss=4.0281 val_loss=0.0000 scale=1.0000 norm=10.9305\n",
      "[iter 200] loss=3.9964 val_loss=0.0000 scale=1.0000 norm=10.6064\n",
      "[iter 300] loss=3.9738 val_loss=0.0000 scale=1.0000 norm=10.3869\n",
      "[iter 400] loss=3.9550 val_loss=0.0000 scale=1.0000 norm=10.2210\n",
      "[iter 0] loss=4.0930 val_loss=0.0000 scale=1.0000 norm=11.5486\n",
      "[iter 100] loss=4.0365 val_loss=0.0000 scale=1.0000 norm=10.9639\n",
      "[iter 200] loss=4.0049 val_loss=0.0000 scale=1.0000 norm=10.6484\n",
      "[iter 300] loss=3.9825 val_loss=0.0000 scale=1.0000 norm=10.4365\n",
      "[iter 400] loss=3.9644 val_loss=0.0000 scale=1.0000 norm=10.2755\n",
      "[iter 0] loss=4.0924 val_loss=0.0000 scale=1.0000 norm=11.5740\n",
      "[iter 100] loss=4.0341 val_loss=0.0000 scale=1.0000 norm=10.9649\n",
      "[iter 200] loss=4.0016 val_loss=0.0000 scale=1.0000 norm=10.6503\n",
      "[iter 300] loss=3.9797 val_loss=0.0000 scale=1.0000 norm=10.4442\n",
      "[iter 400] loss=3.9619 val_loss=0.0000 scale=1.0000 norm=10.2827\n",
      "[iter 0] loss=4.0971 val_loss=0.0000 scale=1.0000 norm=11.6012\n",
      "[iter 100] loss=4.0331 val_loss=0.0000 scale=1.0000 norm=10.9091\n",
      "[iter 200] loss=4.0003 val_loss=0.0000 scale=1.0000 norm=10.5789\n",
      "[iter 300] loss=3.9770 val_loss=0.0000 scale=1.0000 norm=10.3604\n",
      "[iter 400] loss=3.9580 val_loss=0.0000 scale=1.0000 norm=10.1938\n",
      "[iter 0] loss=4.0972 val_loss=0.0000 scale=1.0000 norm=11.6172\n",
      "[iter 100] loss=4.0388 val_loss=0.0000 scale=1.0000 norm=10.9741\n",
      "[iter 200] loss=4.0072 val_loss=0.0000 scale=1.0000 norm=10.6531\n",
      "[iter 300] loss=3.9850 val_loss=0.0000 scale=1.0000 norm=10.4395\n",
      "[iter 400] loss=3.9665 val_loss=0.0000 scale=1.0000 norm=10.2700\n",
      "[iter 0] loss=4.0836 val_loss=0.0000 scale=1.0000 norm=11.5145\n",
      "[iter 100] loss=4.0281 val_loss=0.0000 scale=1.0000 norm=10.9305\n",
      "[iter 200] loss=3.9964 val_loss=0.0000 scale=1.0000 norm=10.6064\n",
      "[iter 300] loss=3.9738 val_loss=0.0000 scale=1.0000 norm=10.3869\n",
      "[iter 400] loss=3.9550 val_loss=0.0000 scale=1.0000 norm=10.2210\n",
      "[iter 0] loss=4.0930 val_loss=0.0000 scale=1.0000 norm=11.5486\n",
      "[iter 100] loss=4.0365 val_loss=0.0000 scale=1.0000 norm=10.9639\n",
      "[iter 200] loss=4.0049 val_loss=0.0000 scale=1.0000 norm=10.6484\n",
      "[iter 300] loss=3.9825 val_loss=0.0000 scale=1.0000 norm=10.4365\n",
      "[iter 400] loss=3.9644 val_loss=0.0000 scale=1.0000 norm=10.2755\n",
      "[iter 0] loss=4.0924 val_loss=0.0000 scale=1.0000 norm=11.5740\n",
      "[iter 100] loss=4.0341 val_loss=0.0000 scale=1.0000 norm=10.9649\n",
      "[iter 200] loss=4.0016 val_loss=0.0000 scale=1.0000 norm=10.6503\n",
      "[iter 300] loss=3.9797 val_loss=0.0000 scale=1.0000 norm=10.4442\n",
      "[iter 400] loss=3.9619 val_loss=0.0000 scale=1.0000 norm=10.2827\n",
      "[iter 0] loss=4.0971 val_loss=0.0000 scale=0.5000 norm=0.4963\n",
      "[iter 100] loss=4.0861 val_loss=0.0000 scale=0.5000 norm=0.4876\n",
      "[iter 200] loss=4.0782 val_loss=0.0000 scale=0.5000 norm=0.4840\n",
      "[iter 300] loss=4.0714 val_loss=0.0000 scale=1.0000 norm=0.9624\n",
      "[iter 400] loss=4.0657 val_loss=0.0000 scale=1.0000 norm=0.9580\n",
      "[iter 0] loss=4.0972 val_loss=0.0000 scale=0.5000 norm=0.4980\n",
      "[iter 100] loss=4.0872 val_loss=0.0000 scale=0.5000 norm=0.4898\n",
      "[iter 200] loss=4.0805 val_loss=0.0000 scale=0.5000 norm=0.4866\n",
      "[iter 300] loss=4.0734 val_loss=0.0000 scale=1.0000 norm=0.9672\n",
      "[iter 400] loss=4.0677 val_loss=0.0000 scale=1.0000 norm=0.9628\n",
      "[iter 0] loss=4.0836 val_loss=0.0000 scale=0.5000 norm=0.4918\n",
      "[iter 100] loss=4.0742 val_loss=0.0000 scale=0.5000 norm=0.4841\n",
      "[iter 200] loss=4.0671 val_loss=0.0000 scale=0.5000 norm=0.4808\n",
      "[iter 300] loss=4.0611 val_loss=0.0000 scale=1.0000 norm=0.9565\n",
      "[iter 400] loss=4.0560 val_loss=0.0000 scale=0.5000 norm=0.4760\n",
      "[iter 0] loss=4.0930 val_loss=0.0000 scale=0.5000 norm=0.4987\n",
      "[iter 100] loss=4.0811 val_loss=0.0000 scale=1.0000 norm=0.9786\n",
      "[iter 200] loss=4.0736 val_loss=0.0000 scale=1.0000 norm=0.9719\n",
      "[iter 300] loss=4.0672 val_loss=0.0000 scale=1.0000 norm=0.9669\n",
      "[iter 400] loss=4.0614 val_loss=0.0000 scale=1.0000 norm=0.9619\n",
      "[iter 0] loss=4.0924 val_loss=0.0000 scale=0.5000 norm=0.4949\n",
      "[iter 100] loss=4.0823 val_loss=0.0000 scale=0.5000 norm=0.4864\n",
      "[iter 200] loss=4.0748 val_loss=0.0000 scale=0.5000 norm=0.4826\n",
      "[iter 300] loss=4.0681 val_loss=0.0000 scale=1.0000 norm=0.9594\n",
      "[iter 400] loss=4.0622 val_loss=0.0000 scale=1.0000 norm=0.9543\n",
      "[iter 0] loss=4.0971 val_loss=0.0000 scale=0.5000 norm=0.4963\n",
      "[iter 100] loss=4.0861 val_loss=0.0000 scale=0.5000 norm=0.4876\n",
      "[iter 200] loss=4.0782 val_loss=0.0000 scale=0.5000 norm=0.4840\n",
      "[iter 300] loss=4.0714 val_loss=0.0000 scale=1.0000 norm=0.9624\n",
      "[iter 400] loss=4.0657 val_loss=0.0000 scale=1.0000 norm=0.9580\n",
      "[iter 0] loss=4.0972 val_loss=0.0000 scale=0.5000 norm=0.4980\n",
      "[iter 100] loss=4.0872 val_loss=0.0000 scale=0.5000 norm=0.4898\n",
      "[iter 200] loss=4.0805 val_loss=0.0000 scale=0.5000 norm=0.4866\n",
      "[iter 300] loss=4.0734 val_loss=0.0000 scale=1.0000 norm=0.9672\n",
      "[iter 400] loss=4.0677 val_loss=0.0000 scale=1.0000 norm=0.9628\n",
      "[iter 0] loss=4.0836 val_loss=0.0000 scale=0.5000 norm=0.4918\n",
      "[iter 100] loss=4.0742 val_loss=0.0000 scale=0.5000 norm=0.4841\n",
      "[iter 200] loss=4.0671 val_loss=0.0000 scale=0.5000 norm=0.4808\n",
      "[iter 300] loss=4.0611 val_loss=0.0000 scale=1.0000 norm=0.9565\n",
      "[iter 400] loss=4.0560 val_loss=0.0000 scale=0.5000 norm=0.4760\n",
      "[iter 0] loss=4.0930 val_loss=0.0000 scale=0.5000 norm=0.4987\n",
      "[iter 100] loss=4.0811 val_loss=0.0000 scale=1.0000 norm=0.9786\n",
      "[iter 200] loss=4.0736 val_loss=0.0000 scale=1.0000 norm=0.9719\n",
      "[iter 300] loss=4.0672 val_loss=0.0000 scale=1.0000 norm=0.9669\n",
      "[iter 400] loss=4.0614 val_loss=0.0000 scale=1.0000 norm=0.9619\n",
      "[iter 0] loss=4.0924 val_loss=0.0000 scale=0.5000 norm=0.4949\n",
      "[iter 100] loss=4.0823 val_loss=0.0000 scale=0.5000 norm=0.4864\n",
      "[iter 200] loss=4.0748 val_loss=0.0000 scale=0.5000 norm=0.4826\n",
      "[iter 300] loss=4.0681 val_loss=0.0000 scale=1.0000 norm=0.9594\n",
      "[iter 400] loss=4.0622 val_loss=0.0000 scale=1.0000 norm=0.9543\n",
      "[iter 0] loss=4.0971 val_loss=0.0000 scale=0.5000 norm=0.4963\n",
      "[iter 100] loss=4.0861 val_loss=0.0000 scale=0.5000 norm=0.4876\n",
      "[iter 200] loss=4.0782 val_loss=0.0000 scale=0.5000 norm=0.4840\n",
      "[iter 300] loss=4.0714 val_loss=0.0000 scale=1.0000 norm=0.9624\n",
      "[iter 400] loss=4.0657 val_loss=0.0000 scale=1.0000 norm=0.9580\n",
      "[iter 0] loss=4.0972 val_loss=0.0000 scale=0.5000 norm=0.4980\n",
      "[iter 100] loss=4.0872 val_loss=0.0000 scale=0.5000 norm=0.4898\n",
      "[iter 200] loss=4.0805 val_loss=0.0000 scale=0.5000 norm=0.4866\n",
      "[iter 300] loss=4.0734 val_loss=0.0000 scale=1.0000 norm=0.9672\n",
      "[iter 400] loss=4.0677 val_loss=0.0000 scale=1.0000 norm=0.9628\n",
      "[iter 0] loss=4.0836 val_loss=0.0000 scale=0.5000 norm=0.4918\n",
      "[iter 100] loss=4.0742 val_loss=0.0000 scale=0.5000 norm=0.4841\n",
      "[iter 200] loss=4.0671 val_loss=0.0000 scale=0.5000 norm=0.4808\n",
      "[iter 300] loss=4.0611 val_loss=0.0000 scale=1.0000 norm=0.9565\n",
      "[iter 400] loss=4.0560 val_loss=0.0000 scale=0.5000 norm=0.4760\n",
      "[iter 0] loss=4.0930 val_loss=0.0000 scale=0.5000 norm=0.4987\n",
      "[iter 100] loss=4.0811 val_loss=0.0000 scale=1.0000 norm=0.9786\n",
      "[iter 200] loss=4.0736 val_loss=0.0000 scale=1.0000 norm=0.9719\n",
      "[iter 300] loss=4.0672 val_loss=0.0000 scale=1.0000 norm=0.9669\n",
      "[iter 400] loss=4.0614 val_loss=0.0000 scale=1.0000 norm=0.9619\n",
      "[iter 0] loss=4.0924 val_loss=0.0000 scale=0.5000 norm=0.4949\n",
      "[iter 100] loss=4.0823 val_loss=0.0000 scale=0.5000 norm=0.4864\n",
      "[iter 200] loss=4.0748 val_loss=0.0000 scale=0.5000 norm=0.4826\n",
      "[iter 300] loss=4.0681 val_loss=0.0000 scale=1.0000 norm=0.9594\n",
      "[iter 400] loss=4.0622 val_loss=0.0000 scale=1.0000 norm=0.9543\n",
      "[iter 0] loss=4.0953 val_loss=0.0000 scale=1.0000 norm=11.6644\n",
      "[iter 100] loss=4.0781 val_loss=0.0000 scale=1.0000 norm=11.4139\n",
      "[iter 200] loss=4.0365 val_loss=0.0000 scale=1.0000 norm=10.9937\n",
      "[iter 300] loss=3.9748 val_loss=0.0000 scale=1.0000 norm=10.2803\n",
      "[iter 400] loss=4.0013 val_loss=0.0000 scale=1.0000 norm=10.6585\n",
      "[iter 0] loss=4.1019 val_loss=0.0000 scale=1.0000 norm=11.7933\n",
      "[iter 100] loss=4.0656 val_loss=0.0000 scale=1.0000 norm=11.3067\n",
      "[iter 200] loss=4.0405 val_loss=0.0000 scale=1.0000 norm=11.0746\n",
      "[iter 300] loss=4.0111 val_loss=0.0000 scale=2.0000 norm=21.4393\n",
      "[iter 400] loss=4.0006 val_loss=0.0000 scale=1.0000 norm=10.6239\n",
      "[iter 0] loss=4.1117 val_loss=0.0000 scale=1.0000 norm=12.0439\n",
      "[iter 100] loss=4.0413 val_loss=0.0000 scale=1.0000 norm=11.1159\n",
      "[iter 200] loss=4.0259 val_loss=0.0000 scale=1.0000 norm=10.9442\n",
      "[iter 300] loss=3.9769 val_loss=0.0000 scale=1.0000 norm=10.3504\n",
      "[iter 400] loss=4.0008 val_loss=0.0000 scale=1.0000 norm=10.6966\n",
      "[iter 0] loss=4.1104 val_loss=0.0000 scale=1.0000 norm=11.9046\n",
      "[iter 100] loss=4.0632 val_loss=0.0000 scale=1.0000 norm=11.3379\n",
      "[iter 200] loss=4.0302 val_loss=0.0000 scale=1.0000 norm=10.9039\n",
      "[iter 300] loss=3.9935 val_loss=0.0000 scale=1.0000 norm=10.5606\n",
      "[iter 400] loss=3.9931 val_loss=0.0000 scale=1.0000 norm=10.5018\n",
      "[iter 0] loss=4.1027 val_loss=0.0000 scale=1.0000 norm=11.7968\n",
      "[iter 100] loss=4.0691 val_loss=0.0000 scale=1.0000 norm=11.4036\n",
      "[iter 200] loss=4.0235 val_loss=0.0000 scale=1.0000 norm=10.8128\n",
      "[iter 300] loss=4.0195 val_loss=0.0000 scale=1.0000 norm=10.8658\n",
      "[iter 400] loss=3.9979 val_loss=0.0000 scale=1.0000 norm=10.6619\n",
      "[iter 0] loss=4.0953 val_loss=0.0000 scale=1.0000 norm=11.6644\n",
      "[iter 100] loss=4.0781 val_loss=0.0000 scale=1.0000 norm=11.4138\n",
      "[iter 200] loss=4.0363 val_loss=0.0000 scale=1.0000 norm=10.9937\n",
      "[iter 300] loss=3.9746 val_loss=0.0000 scale=1.0000 norm=10.2803\n",
      "[iter 400] loss=4.0013 val_loss=0.0000 scale=1.0000 norm=10.6584\n",
      "[iter 0] loss=4.1019 val_loss=0.0000 scale=1.0000 norm=11.7933\n",
      "[iter 100] loss=4.0656 val_loss=0.0000 scale=1.0000 norm=11.3067\n",
      "[iter 200] loss=4.0406 val_loss=0.0000 scale=1.0000 norm=11.0746\n",
      "[iter 300] loss=4.0110 val_loss=0.0000 scale=2.0000 norm=21.4366\n",
      "[iter 400] loss=4.0009 val_loss=0.0000 scale=1.0000 norm=10.6269\n",
      "[iter 0] loss=4.1117 val_loss=0.0000 scale=1.0000 norm=12.0439\n",
      "[iter 100] loss=4.0413 val_loss=0.0000 scale=1.0000 norm=11.1159\n",
      "[iter 200] loss=4.0261 val_loss=0.0000 scale=1.0000 norm=10.9442\n",
      "[iter 300] loss=3.9766 val_loss=0.0000 scale=1.0000 norm=10.3504\n",
      "[iter 400] loss=4.0004 val_loss=0.0000 scale=1.0000 norm=10.6952\n",
      "[iter 0] loss=4.1104 val_loss=0.0000 scale=1.0000 norm=11.9046\n",
      "[iter 100] loss=4.0633 val_loss=0.0000 scale=1.0000 norm=11.3379\n",
      "[iter 200] loss=4.0303 val_loss=0.0000 scale=1.0000 norm=10.9039\n",
      "[iter 300] loss=3.9932 val_loss=0.0000 scale=1.0000 norm=10.5581\n",
      "[iter 400] loss=3.9931 val_loss=0.0000 scale=1.0000 norm=10.5001\n",
      "[iter 0] loss=4.1027 val_loss=0.0000 scale=1.0000 norm=11.7968\n",
      "[iter 100] loss=4.0690 val_loss=0.0000 scale=1.0000 norm=11.4036\n",
      "[iter 200] loss=4.0233 val_loss=0.0000 scale=1.0000 norm=10.8130\n",
      "[iter 300] loss=4.0195 val_loss=0.0000 scale=1.0000 norm=10.8657\n",
      "[iter 400] loss=3.9976 val_loss=0.0000 scale=1.0000 norm=10.6618\n",
      "[iter 0] loss=4.0953 val_loss=0.0000 scale=1.0000 norm=11.6644\n",
      "[iter 100] loss=4.0781 val_loss=0.0000 scale=1.0000 norm=11.4139\n",
      "[iter 200] loss=4.0364 val_loss=0.0000 scale=1.0000 norm=10.9937\n",
      "[iter 300] loss=3.9748 val_loss=0.0000 scale=1.0000 norm=10.2803\n",
      "[iter 400] loss=4.0012 val_loss=0.0000 scale=1.0000 norm=10.6595\n",
      "[iter 0] loss=4.1019 val_loss=0.0000 scale=1.0000 norm=11.7933\n",
      "[iter 100] loss=4.0657 val_loss=0.0000 scale=1.0000 norm=11.3067\n",
      "[iter 200] loss=4.0405 val_loss=0.0000 scale=1.0000 norm=11.0754\n",
      "[iter 300] loss=4.0112 val_loss=0.0000 scale=2.0000 norm=21.4432\n",
      "[iter 400] loss=4.0005 val_loss=0.0000 scale=1.0000 norm=10.6277\n",
      "[iter 0] loss=4.1117 val_loss=0.0000 scale=1.0000 norm=12.0439\n",
      "[iter 100] loss=4.0413 val_loss=0.0000 scale=1.0000 norm=11.1159\n",
      "[iter 200] loss=4.0259 val_loss=0.0000 scale=1.0000 norm=10.9442\n",
      "[iter 300] loss=3.9767 val_loss=0.0000 scale=1.0000 norm=10.3504\n",
      "[iter 400] loss=4.0008 val_loss=0.0000 scale=1.0000 norm=10.6968\n",
      "[iter 0] loss=4.1104 val_loss=0.0000 scale=1.0000 norm=11.9046\n",
      "[iter 100] loss=4.0634 val_loss=0.0000 scale=1.0000 norm=11.3379\n",
      "[iter 200] loss=4.0301 val_loss=0.0000 scale=1.0000 norm=10.9039\n",
      "[iter 300] loss=3.9933 val_loss=0.0000 scale=1.0000 norm=10.5606\n",
      "[iter 400] loss=3.9935 val_loss=0.0000 scale=1.0000 norm=10.5021\n",
      "[iter 0] loss=4.1027 val_loss=0.0000 scale=1.0000 norm=11.7968\n",
      "[iter 100] loss=4.0689 val_loss=0.0000 scale=1.0000 norm=11.4036\n",
      "[iter 200] loss=4.0232 val_loss=0.0000 scale=1.0000 norm=10.8128\n",
      "[iter 300] loss=4.0194 val_loss=0.0000 scale=1.0000 norm=10.8658\n",
      "[iter 400] loss=3.9978 val_loss=0.0000 scale=1.0000 norm=10.6617\n",
      "[iter 0] loss=4.0953 val_loss=0.0000 scale=0.5000 norm=0.4916\n",
      "[iter 100] loss=4.1100 val_loss=0.0000 scale=0.5000 norm=0.5061\n",
      "[iter 200] loss=4.0923 val_loss=0.0000 scale=0.5000 norm=0.4878\n",
      "[iter 300] loss=4.0490 val_loss=0.0000 scale=1.0000 norm=0.9175\n",
      "[iter 400] loss=4.0864 val_loss=0.0000 scale=0.5000 norm=0.4819\n",
      "[iter 0] loss=4.1019 val_loss=0.0000 scale=0.5000 norm=0.4898\n",
      "[iter 100] loss=4.0975 val_loss=0.0000 scale=0.5000 norm=0.4989\n",
      "[iter 200] loss=4.0893 val_loss=0.0000 scale=0.5000 norm=0.4849\n",
      "[iter 300] loss=4.0803 val_loss=0.0000 scale=0.5000 norm=0.4821\n",
      "[iter 400] loss=4.0837 val_loss=0.0000 scale=0.5000 norm=0.4882\n",
      "[iter 0] loss=4.1117 val_loss=0.0000 scale=0.5000 norm=0.4894\n",
      "[iter 100] loss=4.0693 val_loss=0.0000 scale=0.5000 norm=0.4798\n",
      "[iter 200] loss=4.0708 val_loss=0.0000 scale=0.5000 norm=0.4747\n",
      "[iter 300] loss=4.0405 val_loss=0.0000 scale=0.5000 norm=0.4616\n",
      "[iter 400] loss=4.0841 val_loss=0.0000 scale=0.5000 norm=0.4893\n",
      "[iter 0] loss=4.1104 val_loss=0.0000 scale=0.5000 norm=0.4918\n",
      "[iter 100] loss=4.0906 val_loss=0.0000 scale=0.5000 norm=0.4919\n",
      "[iter 200] loss=4.0746 val_loss=0.0000 scale=0.5000 norm=0.4856\n",
      "[iter 300] loss=4.0540 val_loss=0.0000 scale=0.5000 norm=0.4652\n",
      "[iter 400] loss=4.0722 val_loss=0.0000 scale=0.5000 norm=0.4885\n",
      "[iter 0] loss=4.1027 val_loss=0.0000 scale=0.5000 norm=0.4908\n",
      "[iter 100] loss=4.1020 val_loss=0.0000 scale=0.5000 norm=0.4946\n",
      "[iter 200] loss=4.0753 val_loss=0.0000 scale=0.5000 norm=0.4855\n",
      "[iter 300] loss=4.0855 val_loss=0.0000 scale=0.5000 norm=0.4831\n",
      "[iter 400] loss=4.0813 val_loss=0.0000 scale=0.5000 norm=0.4830\n",
      "[iter 0] loss=4.0953 val_loss=0.0000 scale=0.5000 norm=0.4916\n",
      "[iter 100] loss=4.1101 val_loss=0.0000 scale=0.5000 norm=0.5063\n",
      "[iter 200] loss=4.0922 val_loss=0.0000 scale=0.5000 norm=0.4877\n",
      "[iter 300] loss=4.0495 val_loss=0.0000 scale=1.0000 norm=0.9187\n",
      "[iter 400] loss=4.0867 val_loss=0.0000 scale=0.5000 norm=0.4819\n",
      "[iter 0] loss=4.1019 val_loss=0.0000 scale=0.5000 norm=0.4898\n",
      "[iter 100] loss=4.0976 val_loss=0.0000 scale=0.5000 norm=0.4991\n",
      "[iter 200] loss=4.0897 val_loss=0.0000 scale=0.5000 norm=0.4853\n",
      "[iter 300] loss=4.0801 val_loss=0.0000 scale=0.5000 norm=0.4819\n",
      "[iter 400] loss=4.0838 val_loss=0.0000 scale=0.5000 norm=0.4879\n",
      "[iter 0] loss=4.1117 val_loss=0.0000 scale=0.5000 norm=0.4894\n",
      "[iter 100] loss=4.0693 val_loss=0.0000 scale=0.5000 norm=0.4799\n",
      "[iter 200] loss=4.0707 val_loss=0.0000 scale=0.5000 norm=0.4747\n",
      "[iter 300] loss=4.0406 val_loss=0.0000 scale=0.5000 norm=0.4617\n",
      "[iter 400] loss=4.0842 val_loss=0.0000 scale=0.5000 norm=0.4895\n",
      "[iter 0] loss=4.1104 val_loss=0.0000 scale=0.5000 norm=0.4918\n",
      "[iter 100] loss=4.0906 val_loss=0.0000 scale=0.5000 norm=0.4920\n",
      "[iter 200] loss=4.0746 val_loss=0.0000 scale=0.5000 norm=0.4856\n",
      "[iter 300] loss=4.0538 val_loss=0.0000 scale=0.5000 norm=0.4649\n",
      "[iter 400] loss=4.0722 val_loss=0.0000 scale=0.5000 norm=0.4886\n",
      "[iter 0] loss=4.1027 val_loss=0.0000 scale=0.5000 norm=0.4908\n",
      "[iter 100] loss=4.1020 val_loss=0.0000 scale=0.5000 norm=0.4945\n",
      "[iter 200] loss=4.0754 val_loss=0.0000 scale=0.5000 norm=0.4855\n",
      "[iter 300] loss=4.0856 val_loss=0.0000 scale=0.5000 norm=0.4832\n",
      "[iter 400] loss=4.0814 val_loss=0.0000 scale=0.5000 norm=0.4833\n",
      "[iter 0] loss=4.0953 val_loss=0.0000 scale=0.5000 norm=0.4916\n",
      "[iter 100] loss=4.1102 val_loss=0.0000 scale=0.5000 norm=0.5063\n",
      "[iter 200] loss=4.0923 val_loss=0.0000 scale=0.5000 norm=0.4877\n",
      "[iter 300] loss=4.0493 val_loss=0.0000 scale=1.0000 norm=0.9181\n",
      "[iter 400] loss=4.0870 val_loss=0.0000 scale=0.5000 norm=0.4825\n",
      "[iter 0] loss=4.1019 val_loss=0.0000 scale=0.5000 norm=0.4898\n",
      "[iter 100] loss=4.0976 val_loss=0.0000 scale=0.5000 norm=0.4990\n",
      "[iter 200] loss=4.0894 val_loss=0.0000 scale=0.5000 norm=0.4850\n",
      "[iter 300] loss=4.0800 val_loss=0.0000 scale=0.5000 norm=0.4819\n",
      "[iter 400] loss=4.0838 val_loss=0.0000 scale=0.5000 norm=0.4883\n",
      "[iter 0] loss=4.1117 val_loss=0.0000 scale=0.5000 norm=0.4894\n",
      "[iter 100] loss=4.0692 val_loss=0.0000 scale=0.5000 norm=0.4797\n",
      "[iter 200] loss=4.0707 val_loss=0.0000 scale=0.5000 norm=0.4747\n",
      "[iter 300] loss=4.0406 val_loss=0.0000 scale=0.5000 norm=0.4619\n",
      "[iter 400] loss=4.0840 val_loss=0.0000 scale=0.5000 norm=0.4892\n",
      "[iter 0] loss=4.1104 val_loss=0.0000 scale=0.5000 norm=0.4918\n",
      "[iter 100] loss=4.0907 val_loss=0.0000 scale=0.5000 norm=0.4921\n",
      "[iter 200] loss=4.0744 val_loss=0.0000 scale=0.5000 norm=0.4853\n",
      "[iter 300] loss=4.0536 val_loss=0.0000 scale=0.5000 norm=0.4647\n",
      "[iter 400] loss=4.0725 val_loss=0.0000 scale=0.5000 norm=0.4889\n",
      "[iter 0] loss=4.1027 val_loss=0.0000 scale=0.5000 norm=0.4908\n",
      "[iter 100] loss=4.1019 val_loss=0.0000 scale=0.5000 norm=0.4944\n",
      "[iter 200] loss=4.0755 val_loss=0.0000 scale=0.5000 norm=0.4856\n",
      "[iter 300] loss=4.0857 val_loss=0.0000 scale=0.5000 norm=0.4832\n",
      "[iter 400] loss=4.0816 val_loss=0.0000 scale=0.5000 norm=0.4835\n",
      "[iter 0] loss=4.0887 val_loss=0.0000 scale=1.0000 norm=11.5815\n",
      "[iter 100] loss=4.0641 val_loss=0.0000 scale=1.0000 norm=11.1885\n",
      "[iter 200] loss=4.0445 val_loss=0.0000 scale=1.0000 norm=11.0198\n",
      "[iter 300] loss=4.0013 val_loss=0.0000 scale=1.0000 norm=10.5661\n",
      "[iter 400] loss=4.0088 val_loss=0.0000 scale=1.0000 norm=10.7229\n",
      "[iter 0] loss=4.1079 val_loss=0.0000 scale=1.0000 norm=11.7758\n",
      "[iter 100] loss=4.0623 val_loss=0.0000 scale=1.0000 norm=11.2475\n",
      "[iter 200] loss=4.0354 val_loss=0.0000 scale=1.0000 norm=10.9808\n",
      "[iter 300] loss=4.0139 val_loss=0.0000 scale=1.0000 norm=10.7591\n",
      "[iter 400] loss=4.0059 val_loss=0.0000 scale=1.0000 norm=10.6939\n",
      "[iter 0] loss=4.1036 val_loss=0.0000 scale=1.0000 norm=11.8357\n",
      "[iter 100] loss=4.0464 val_loss=0.0000 scale=1.0000 norm=11.1430\n",
      "[iter 200] loss=4.0223 val_loss=0.0000 scale=1.0000 norm=10.8892\n",
      "[iter 300] loss=3.9860 val_loss=0.0000 scale=1.0000 norm=10.5092\n",
      "[iter 400] loss=4.0009 val_loss=0.0000 scale=1.0000 norm=10.7296\n",
      "[iter 0] loss=4.1035 val_loss=0.0000 scale=1.0000 norm=11.7229\n",
      "[iter 100] loss=4.0581 val_loss=0.0000 scale=1.0000 norm=11.2419\n",
      "[iter 200] loss=4.0290 val_loss=0.0000 scale=1.0000 norm=10.8596\n",
      "[iter 300] loss=3.9999 val_loss=0.0000 scale=1.0000 norm=10.6304\n",
      "[iter 400] loss=4.0035 val_loss=0.0000 scale=1.0000 norm=10.6788\n",
      "[iter 0] loss=4.1023 val_loss=0.0000 scale=1.0000 norm=11.7478\n",
      "[iter 100] loss=4.0608 val_loss=0.0000 scale=1.0000 norm=11.2952\n",
      "[iter 200] loss=4.0175 val_loss=0.0000 scale=1.0000 norm=10.7052\n",
      "[iter 300] loss=4.0073 val_loss=0.0000 scale=1.0000 norm=10.6941\n",
      "[iter 400] loss=4.0049 val_loss=0.0000 scale=1.0000 norm=10.7446\n",
      "[iter 0] loss=4.0887 val_loss=0.0000 scale=1.0000 norm=11.5815\n",
      "[iter 100] loss=4.0641 val_loss=0.0000 scale=1.0000 norm=11.1885\n",
      "[iter 200] loss=4.0445 val_loss=0.0000 scale=1.0000 norm=11.0198\n",
      "[iter 300] loss=4.0013 val_loss=0.0000 scale=1.0000 norm=10.5661\n",
      "[iter 400] loss=4.0087 val_loss=0.0000 scale=1.0000 norm=10.7229\n",
      "[iter 0] loss=4.1079 val_loss=0.0000 scale=1.0000 norm=11.7758\n",
      "[iter 100] loss=4.0623 val_loss=0.0000 scale=1.0000 norm=11.2475\n",
      "[iter 200] loss=4.0354 val_loss=0.0000 scale=1.0000 norm=10.9808\n",
      "[iter 300] loss=4.0139 val_loss=0.0000 scale=1.0000 norm=10.7591\n",
      "[iter 400] loss=4.0059 val_loss=0.0000 scale=1.0000 norm=10.6939\n",
      "[iter 0] loss=4.1036 val_loss=0.0000 scale=1.0000 norm=11.8357\n",
      "[iter 100] loss=4.0466 val_loss=0.0000 scale=1.0000 norm=11.1431\n",
      "[iter 200] loss=4.0224 val_loss=0.0000 scale=1.0000 norm=10.8892\n",
      "[iter 300] loss=3.9860 val_loss=0.0000 scale=1.0000 norm=10.5092\n",
      "[iter 400] loss=4.0010 val_loss=0.0000 scale=1.0000 norm=10.7296\n",
      "[iter 0] loss=4.1035 val_loss=0.0000 scale=1.0000 norm=11.7229\n",
      "[iter 100] loss=4.0581 val_loss=0.0000 scale=1.0000 norm=11.2419\n",
      "[iter 200] loss=4.0289 val_loss=0.0000 scale=1.0000 norm=10.8596\n",
      "[iter 300] loss=3.9999 val_loss=0.0000 scale=1.0000 norm=10.6304\n",
      "[iter 400] loss=4.0035 val_loss=0.0000 scale=1.0000 norm=10.6786\n",
      "[iter 0] loss=4.1023 val_loss=0.0000 scale=1.0000 norm=11.7478\n",
      "[iter 100] loss=4.0608 val_loss=0.0000 scale=1.0000 norm=11.2952\n",
      "[iter 200] loss=4.0175 val_loss=0.0000 scale=1.0000 norm=10.7052\n",
      "[iter 300] loss=4.0074 val_loss=0.0000 scale=1.0000 norm=10.6937\n",
      "[iter 400] loss=4.0048 val_loss=0.0000 scale=1.0000 norm=10.7441\n",
      "[iter 0] loss=4.0887 val_loss=0.0000 scale=1.0000 norm=11.5815\n",
      "[iter 100] loss=4.0641 val_loss=0.0000 scale=1.0000 norm=11.1885\n",
      "[iter 200] loss=4.0445 val_loss=0.0000 scale=1.0000 norm=11.0198\n",
      "[iter 300] loss=4.0012 val_loss=0.0000 scale=1.0000 norm=10.5661\n",
      "[iter 400] loss=4.0084 val_loss=0.0000 scale=1.0000 norm=10.7217\n",
      "[iter 0] loss=4.1079 val_loss=0.0000 scale=1.0000 norm=11.7758\n",
      "[iter 100] loss=4.0623 val_loss=0.0000 scale=1.0000 norm=11.2475\n",
      "[iter 200] loss=4.0354 val_loss=0.0000 scale=1.0000 norm=10.9808\n",
      "[iter 300] loss=4.0141 val_loss=0.0000 scale=1.0000 norm=10.7619\n",
      "[iter 400] loss=4.0063 val_loss=0.0000 scale=1.0000 norm=10.6977\n",
      "[iter 0] loss=4.1036 val_loss=0.0000 scale=1.0000 norm=11.8357\n",
      "[iter 100] loss=4.0466 val_loss=0.0000 scale=1.0000 norm=11.1431\n",
      "[iter 200] loss=4.0224 val_loss=0.0000 scale=1.0000 norm=10.8892\n",
      "[iter 300] loss=3.9860 val_loss=0.0000 scale=1.0000 norm=10.5092\n",
      "[iter 400] loss=4.0009 val_loss=0.0000 scale=1.0000 norm=10.7296\n",
      "[iter 0] loss=4.1035 val_loss=0.0000 scale=1.0000 norm=11.7229\n",
      "[iter 100] loss=4.0582 val_loss=0.0000 scale=1.0000 norm=11.2419\n",
      "[iter 200] loss=4.0290 val_loss=0.0000 scale=1.0000 norm=10.8596\n",
      "[iter 300] loss=4.0000 val_loss=0.0000 scale=1.0000 norm=10.6304\n",
      "[iter 400] loss=4.0035 val_loss=0.0000 scale=1.0000 norm=10.6788\n",
      "[iter 0] loss=4.1023 val_loss=0.0000 scale=1.0000 norm=11.7478\n",
      "[iter 100] loss=4.0608 val_loss=0.0000 scale=1.0000 norm=11.2952\n",
      "[iter 200] loss=4.0175 val_loss=0.0000 scale=1.0000 norm=10.7052\n",
      "[iter 300] loss=4.0073 val_loss=0.0000 scale=1.0000 norm=10.6941\n",
      "[iter 400] loss=4.0049 val_loss=0.0000 scale=1.0000 norm=10.7446\n",
      "[iter 0] loss=4.0887 val_loss=0.0000 scale=0.5000 norm=0.4880\n",
      "[iter 100] loss=4.0964 val_loss=0.0000 scale=0.5000 norm=0.5015\n",
      "[iter 200] loss=4.0983 val_loss=0.0000 scale=0.5000 norm=0.4988\n",
      "[iter 300] loss=4.0687 val_loss=0.0000 scale=1.0000 norm=0.9539\n",
      "[iter 400] loss=4.0891 val_loss=0.0000 scale=0.5000 norm=0.4856\n",
      "[iter 0] loss=4.1079 val_loss=0.0000 scale=0.5000 norm=0.5021\n",
      "[iter 100] loss=4.0932 val_loss=0.0000 scale=0.5000 norm=0.4951\n",
      "[iter 200] loss=4.0848 val_loss=0.0000 scale=0.5000 norm=0.4838\n",
      "[iter 300] loss=4.0822 val_loss=0.0000 scale=0.5000 norm=0.4868\n",
      "[iter 400] loss=4.0857 val_loss=0.0000 scale=0.5000 norm=0.4879\n",
      "[iter 0] loss=4.1036 val_loss=0.0000 scale=0.5000 norm=0.4960\n",
      "[iter 100] loss=4.0747 val_loss=0.0000 scale=0.5000 norm=0.4842\n",
      "[iter 200] loss=4.0696 val_loss=0.0000 scale=0.5000 norm=0.4781\n",
      "[iter 300] loss=4.0478 val_loss=0.0000 scale=0.5000 norm=0.4673\n",
      "[iter 400] loss=4.0779 val_loss=0.0000 scale=0.5000 norm=0.4826\n",
      "[iter 0] loss=4.1035 val_loss=0.0000 scale=0.5000 norm=0.4996\n",
      "[iter 100] loss=4.0849 val_loss=0.0000 scale=0.5000 norm=0.4888\n",
      "[iter 200] loss=4.0759 val_loss=0.0000 scale=0.5000 norm=0.4890\n",
      "[iter 300] loss=4.0608 val_loss=0.0000 scale=0.5000 norm=0.4751\n",
      "[iter 400] loss=4.0774 val_loss=0.0000 scale=0.5000 norm=0.4866\n",
      "[iter 0] loss=4.1023 val_loss=0.0000 scale=0.5000 norm=0.4949\n",
      "[iter 100] loss=4.0914 val_loss=0.0000 scale=0.5000 norm=0.4880\n",
      "[iter 200] loss=4.0702 val_loss=0.0000 scale=0.5000 norm=0.4858\n",
      "[iter 300] loss=4.0716 val_loss=0.0000 scale=1.0000 norm=0.9611\n",
      "[iter 400] loss=4.0813 val_loss=0.0000 scale=0.5000 norm=0.4805\n",
      "[iter 0] loss=4.0887 val_loss=0.0000 scale=0.5000 norm=0.4880\n",
      "[iter 100] loss=4.0965 val_loss=0.0000 scale=0.5000 norm=0.5017\n",
      "[iter 200] loss=4.0982 val_loss=0.0000 scale=0.5000 norm=0.4986\n",
      "[iter 300] loss=4.0689 val_loss=0.0000 scale=1.0000 norm=0.9545\n",
      "[iter 400] loss=4.0892 val_loss=0.0000 scale=0.5000 norm=0.4857\n",
      "[iter 0] loss=4.1079 val_loss=0.0000 scale=0.5000 norm=0.5021\n",
      "[iter 100] loss=4.0932 val_loss=0.0000 scale=0.5000 norm=0.4952\n",
      "[iter 200] loss=4.0848 val_loss=0.0000 scale=0.5000 norm=0.4839\n",
      "[iter 300] loss=4.0821 val_loss=0.0000 scale=0.5000 norm=0.4867\n",
      "[iter 400] loss=4.0856 val_loss=0.0000 scale=0.5000 norm=0.4879\n",
      "[iter 0] loss=4.1036 val_loss=0.0000 scale=0.5000 norm=0.4960\n",
      "[iter 100] loss=4.0747 val_loss=0.0000 scale=0.5000 norm=0.4842\n",
      "[iter 200] loss=4.0696 val_loss=0.0000 scale=0.5000 norm=0.4781\n",
      "[iter 300] loss=4.0478 val_loss=0.0000 scale=0.5000 norm=0.4673\n",
      "[iter 400] loss=4.0779 val_loss=0.0000 scale=0.5000 norm=0.4825\n",
      "[iter 0] loss=4.1035 val_loss=0.0000 scale=0.5000 norm=0.4996\n",
      "[iter 100] loss=4.0848 val_loss=0.0000 scale=0.5000 norm=0.4888\n",
      "[iter 200] loss=4.0759 val_loss=0.0000 scale=0.5000 norm=0.4891\n",
      "[iter 300] loss=4.0608 val_loss=0.0000 scale=0.5000 norm=0.4752\n",
      "[iter 400] loss=4.0773 val_loss=0.0000 scale=0.5000 norm=0.4866\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages/ngboost/ngboost.py:321\u001b[0m, in \u001b[0;36mNGBoost.fit\u001b[0;34m(self, X, Y, X_val, Y_val, sample_weight, val_sample_weight, train_loss_monitor, val_loss_monitor, early_stopping_rounds)\u001b[0m\n\u001b[1;32m    315\u001b[0m scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_search(proj_grad, P_batch, Y_batch, weight_batch)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# pdb.set_trace()\u001b[39;00m\n\u001b[1;32m    318\u001b[0m params \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;241m*\u001b[39m scale\n\u001b[0;32m--> 321\u001b[0m     \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39marray([m\u001b[38;5;241m.\u001b[39mpredict(X[:, col_idx]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_models[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    322\u001b[0m )\n\u001b[1;32m    324\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m Y_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages/ngboost/ngboost.py:321\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    315\u001b[0m scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_search(proj_grad, P_batch, Y_batch, weight_batch)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# pdb.set_trace()\u001b[39;00m\n\u001b[1;32m    318\u001b[0m params \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;241m*\u001b[39m scale\n\u001b[0;32m--> 321\u001b[0m     \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_models[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    322\u001b[0m )\n\u001b[1;32m    324\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m Y_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages/sklearn/tree/_classes.py:426\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict class or regression value for X.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \n\u001b[1;32m    405\u001b[0m \u001b[38;5;124;03mFor a classification model, the predicted class for each sample in X is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;124;03m    The predicted classes, or the predict values.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    425\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 426\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m    428\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages/sklearn/tree/_classes.py:392\u001b[0m, in \u001b[0;36mBaseDecisionTree._validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_input:\n\u001b[0;32m--> 392\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    394\u001b[0m         X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc\n\u001b[1;32m    395\u001b[0m     ):\n\u001b[1;32m    396\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages/sklearn/base.py:546\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 546\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    547\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages/sklearn/utils/validation.py:821\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforce_all_finite should be a bool or \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             force_all_finite\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m estimator_name \u001b[38;5;241m=\u001b[39m \u001b[43m_check_estimator_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    822\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m estimator_name \u001b[38;5;28;01mif\u001b[39;00m estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;66;03m# When all dataframe columns are sparse, convert to a sparse array\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages/sklearn/utils/validation.py:581\u001b[0m, in \u001b[0;36m_check_estimator_name\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    573\u001b[0m         \u001b[38;5;28mhasattr\u001b[39m(array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m     ):\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array))\n\u001b[0;32m--> 581\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_estimator_name\u001b[39m(estimator):\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    583\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(estimator, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "44718df4-70e0-4ef7-bc29-a8ecca2330d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_params\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params'"
     ]
    }
   ],
   "source": [
    "grid_search.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c98c1-4d34-4849-81e7-8ebf14fcc529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b60b94a88b06cb6055855c21d204c5d44d1f1cdd16a36317c55022353c0fb7c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
