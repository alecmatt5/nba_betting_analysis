{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e5ec10b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e05b0d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a56d66ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in /home/alec/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (0.2.7)\n",
      "Requirement already satisfied: cloudpickle in /home/alec/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from hyperopt) (2.2.1)\n",
      "Requirement already satisfied: future in /home/alec/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from hyperopt) (0.18.3)\n",
      "Requirement already satisfied: scipy in /home/alec/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from hyperopt) (1.10.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/alec/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from hyperopt) (3.0)\n",
      "Requirement already satisfied: py4j in /home/alec/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from hyperopt) (0.10.9.7)\n",
      "Requirement already satisfied: numpy in /home/alec/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from hyperopt) (1.24.2)\n",
      "Requirement already satisfied: six in /home/alec/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from hyperopt) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /home/alec/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from hyperopt) (4.65.0)\n",
      "Requirement already satisfied: xgboost in /home/alec/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (1.7.4)\n",
      "Requirement already satisfied: numpy in /home/alec/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from xgboost) (1.24.2)\n",
      "Requirement already satisfied: scipy in /home/alec/.pyenv/versions/3.10.6/envs/nba_betting_analysis/lib/python3.10/site-packages (from xgboost) (1.10.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperopt\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c81cdbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "from xgboost import DMatrix, XGBRegressor\n",
    "from hyperopt import Trials, STATUS_OK, tpe, hp, fmin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514fa995",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08b23147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER_ID</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>PLAYER_NAME</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "      <th>AST_PCT</th>\n",
       "      <th>AST_RATIO</th>\n",
       "      <th>AST_TOV</th>\n",
       "      <th>DEF_RATING</th>\n",
       "      <th>DREB_PCT</th>\n",
       "      <th>EFG_PCT</th>\n",
       "      <th>...</th>\n",
       "      <th>OFF_RATING</th>\n",
       "      <th>OREB_PCT</th>\n",
       "      <th>PACE</th>\n",
       "      <th>PIE</th>\n",
       "      <th>POSS</th>\n",
       "      <th>PTS</th>\n",
       "      <th>REB_PCT</th>\n",
       "      <th>TM_TOV_PCT</th>\n",
       "      <th>TS_PCT</th>\n",
       "      <th>USG_PCT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1713</td>\n",
       "      <td>2018-12-03</td>\n",
       "      <td>Vince Carter</td>\n",
       "      <td>-14.9</td>\n",
       "      <td>0.123266</td>\n",
       "      <td>0.169653</td>\n",
       "      <td>0.042814</td>\n",
       "      <td>0.578202</td>\n",
       "      <td>0.250375</td>\n",
       "      <td>0.402074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587002</td>\n",
       "      <td>0.050330</td>\n",
       "      <td>0.014105</td>\n",
       "      <td>0.542849</td>\n",
       "      <td>0.347285</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.228959</td>\n",
       "      <td>0.072430</td>\n",
       "      <td>0.431366</td>\n",
       "      <td>0.376921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1713</td>\n",
       "      <td>2018-12-05</td>\n",
       "      <td>Vince Carter</td>\n",
       "      <td>-14.8</td>\n",
       "      <td>0.132462</td>\n",
       "      <td>0.147789</td>\n",
       "      <td>0.042814</td>\n",
       "      <td>0.546110</td>\n",
       "      <td>0.255056</td>\n",
       "      <td>0.432649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573205</td>\n",
       "      <td>0.064214</td>\n",
       "      <td>0.013059</td>\n",
       "      <td>0.548627</td>\n",
       "      <td>0.383484</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.072430</td>\n",
       "      <td>0.465736</td>\n",
       "      <td>0.384718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1713</td>\n",
       "      <td>2018-12-08</td>\n",
       "      <td>Vince Carter</td>\n",
       "      <td>-13.9</td>\n",
       "      <td>0.147144</td>\n",
       "      <td>0.161434</td>\n",
       "      <td>0.057086</td>\n",
       "      <td>0.548544</td>\n",
       "      <td>0.268539</td>\n",
       "      <td>0.466538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577199</td>\n",
       "      <td>0.083652</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>0.554863</td>\n",
       "      <td>0.373303</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.249472</td>\n",
       "      <td>0.090059</td>\n",
       "      <td>0.499260</td>\n",
       "      <td>0.418802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1713</td>\n",
       "      <td>2018-12-12</td>\n",
       "      <td>Vince Carter</td>\n",
       "      <td>-13.9</td>\n",
       "      <td>0.125686</td>\n",
       "      <td>0.163571</td>\n",
       "      <td>0.014271</td>\n",
       "      <td>0.554043</td>\n",
       "      <td>0.256742</td>\n",
       "      <td>0.414582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561224</td>\n",
       "      <td>0.065255</td>\n",
       "      <td>0.014036</td>\n",
       "      <td>0.548169</td>\n",
       "      <td>0.368778</td>\n",
       "      <td>0.445312</td>\n",
       "      <td>0.231071</td>\n",
       "      <td>0.070731</td>\n",
       "      <td>0.447864</td>\n",
       "      <td>0.404767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1713</td>\n",
       "      <td>2018-12-14</td>\n",
       "      <td>Vince Carter</td>\n",
       "      <td>-11.5</td>\n",
       "      <td>0.125686</td>\n",
       "      <td>0.163571</td>\n",
       "      <td>0.014271</td>\n",
       "      <td>0.595691</td>\n",
       "      <td>0.256742</td>\n",
       "      <td>0.396729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566125</td>\n",
       "      <td>0.047900</td>\n",
       "      <td>0.013775</td>\n",
       "      <td>0.547654</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>0.474609</td>\n",
       "      <td>0.221418</td>\n",
       "      <td>0.070731</td>\n",
       "      <td>0.422377</td>\n",
       "      <td>0.418133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100079</th>\n",
       "      <td>1631323</td>\n",
       "      <td>2023-02-23</td>\n",
       "      <td>Simone Fontecchio</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.092611</td>\n",
       "      <td>0.167352</td>\n",
       "      <td>0.071357</td>\n",
       "      <td>0.566844</td>\n",
       "      <td>0.141199</td>\n",
       "      <td>0.415758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.706635</td>\n",
       "      <td>0.133287</td>\n",
       "      <td>0.012827</td>\n",
       "      <td>0.522883</td>\n",
       "      <td>0.263575</td>\n",
       "      <td>0.759766</td>\n",
       "      <td>0.171342</td>\n",
       "      <td>0.267842</td>\n",
       "      <td>0.421003</td>\n",
       "      <td>0.387391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100080</th>\n",
       "      <td>1631323</td>\n",
       "      <td>2023-02-25</td>\n",
       "      <td>Simone Fontecchio</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.107293</td>\n",
       "      <td>0.190860</td>\n",
       "      <td>0.071357</td>\n",
       "      <td>0.579735</td>\n",
       "      <td>0.141199</td>\n",
       "      <td>0.429121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.770627</td>\n",
       "      <td>0.152725</td>\n",
       "      <td>0.012945</td>\n",
       "      <td>0.538387</td>\n",
       "      <td>0.277149</td>\n",
       "      <td>0.761719</td>\n",
       "      <td>0.182202</td>\n",
       "      <td>0.214741</td>\n",
       "      <td>0.455690</td>\n",
       "      <td>0.367788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100081</th>\n",
       "      <td>1631323</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>Simone Fontecchio</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.128751</td>\n",
       "      <td>0.218313</td>\n",
       "      <td>0.080919</td>\n",
       "      <td>0.630758</td>\n",
       "      <td>0.094382</td>\n",
       "      <td>0.375668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761732</td>\n",
       "      <td>0.152725</td>\n",
       "      <td>0.012803</td>\n",
       "      <td>0.522654</td>\n",
       "      <td>0.319005</td>\n",
       "      <td>0.699219</td>\n",
       "      <td>0.139065</td>\n",
       "      <td>0.267842</td>\n",
       "      <td>0.402813</td>\n",
       "      <td>0.317665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100082</th>\n",
       "      <td>1631323</td>\n",
       "      <td>2023-03-03</td>\n",
       "      <td>Simone Fontecchio</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>0.139561</td>\n",
       "      <td>0.228670</td>\n",
       "      <td>0.095191</td>\n",
       "      <td>0.612729</td>\n",
       "      <td>0.045880</td>\n",
       "      <td>0.277635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773260</td>\n",
       "      <td>0.096147</td>\n",
       "      <td>0.011583</td>\n",
       "      <td>0.523112</td>\n",
       "      <td>0.369910</td>\n",
       "      <td>0.666016</td>\n",
       "      <td>0.080543</td>\n",
       "      <td>0.139550</td>\n",
       "      <td>0.305626</td>\n",
       "      <td>0.312542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100083</th>\n",
       "      <td>1631323</td>\n",
       "      <td>2023-03-05</td>\n",
       "      <td>Simone Fontecchio</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>0.168925</td>\n",
       "      <td>0.265165</td>\n",
       "      <td>0.095191</td>\n",
       "      <td>0.641936</td>\n",
       "      <td>0.060300</td>\n",
       "      <td>0.315801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687574</td>\n",
       "      <td>0.096147</td>\n",
       "      <td>0.011432</td>\n",
       "      <td>0.523112</td>\n",
       "      <td>0.408371</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.090498</td>\n",
       "      <td>0.139550</td>\n",
       "      <td>0.343380</td>\n",
       "      <td>0.350635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100084 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PLAYER_ID  GAME_DATE        PLAYER_NAME  PLUS_MINUS   AST_PCT  \\\n",
       "0           1713 2018-12-03       Vince Carter       -14.9  0.123266   \n",
       "1           1713 2018-12-05       Vince Carter       -14.8  0.132462   \n",
       "2           1713 2018-12-08       Vince Carter       -13.9  0.147144   \n",
       "3           1713 2018-12-12       Vince Carter       -13.9  0.125686   \n",
       "4           1713 2018-12-14       Vince Carter       -11.5  0.125686   \n",
       "...          ...        ...                ...         ...       ...   \n",
       "100079   1631323 2023-02-23  Simone Fontecchio         0.6  0.092611   \n",
       "100080   1631323 2023-02-25  Simone Fontecchio         2.3  0.107293   \n",
       "100081   1631323 2023-02-28  Simone Fontecchio        -0.8  0.128751   \n",
       "100082   1631323 2023-03-03  Simone Fontecchio        -5.3  0.139561   \n",
       "100083   1631323 2023-03-05  Simone Fontecchio        -5.3  0.168925   \n",
       "\n",
       "        AST_RATIO   AST_TOV  DEF_RATING  DREB_PCT   EFG_PCT  ...  OFF_RATING  \\\n",
       "0        0.169653  0.042814    0.578202  0.250375  0.402074  ...    0.587002   \n",
       "1        0.147789  0.042814    0.546110  0.255056  0.432649  ...    0.573205   \n",
       "2        0.161434  0.057086    0.548544  0.268539  0.466538  ...    0.577199   \n",
       "3        0.163571  0.014271    0.554043  0.256742  0.414582  ...    0.561224   \n",
       "4        0.163571  0.014271    0.595691  0.256742  0.396729  ...    0.566125   \n",
       "...           ...       ...         ...       ...       ...  ...         ...   \n",
       "100079   0.167352  0.071357    0.566844  0.141199  0.415758  ...    0.706635   \n",
       "100080   0.190860  0.071357    0.579735  0.141199  0.429121  ...    0.770627   \n",
       "100081   0.218313  0.080919    0.630758  0.094382  0.375668  ...    0.761732   \n",
       "100082   0.228670  0.095191    0.612729  0.045880  0.277635  ...    0.773260   \n",
       "100083   0.265165  0.095191    0.641936  0.060300  0.315801  ...    0.687574   \n",
       "\n",
       "        OREB_PCT      PACE       PIE      POSS       PTS   REB_PCT  \\\n",
       "0       0.050330  0.014105  0.542849  0.347285  0.421875  0.228959   \n",
       "1       0.064214  0.013059  0.548627  0.383484  0.437500  0.231373   \n",
       "2       0.083652  0.013363  0.554863  0.373303  0.437500  0.249472   \n",
       "3       0.065255  0.014036  0.548169  0.368778  0.445312  0.231071   \n",
       "4       0.047900  0.013775  0.547654  0.367647  0.474609  0.221418   \n",
       "...          ...       ...       ...       ...       ...       ...   \n",
       "100079  0.133287  0.012827  0.522883  0.263575  0.759766  0.171342   \n",
       "100080  0.152725  0.012945  0.538387  0.277149  0.761719  0.182202   \n",
       "100081  0.152725  0.012803  0.522654  0.319005  0.699219  0.139065   \n",
       "100082  0.096147  0.011583  0.523112  0.369910  0.666016  0.080543   \n",
       "100083  0.096147  0.011432  0.523112  0.408371  0.656250  0.090498   \n",
       "\n",
       "        TM_TOV_PCT    TS_PCT   USG_PCT  \n",
       "0         0.072430  0.431366  0.376921  \n",
       "1         0.072430  0.465736  0.384718  \n",
       "2         0.090059  0.499260  0.418802  \n",
       "3         0.070731  0.447864  0.404767  \n",
       "4         0.070731  0.422377  0.418133  \n",
       "...            ...       ...       ...  \n",
       "100079    0.267842  0.421003  0.387391  \n",
       "100080    0.214741  0.455690  0.367788  \n",
       "100081    0.267842  0.402813  0.317665  \n",
       "100082    0.139550  0.305626  0.312542  \n",
       "100083    0.139550  0.343380  0.350635  \n",
       "\n",
       "[100084 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../data/pkl/scaled_boxscore_advanced_rolling_players.pkl')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f2a7f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PLAYER_ID            category\n",
       "GAME_DATE      datetime64[ns]\n",
       "PLAYER_NAME          category\n",
       "PLUS_MINUS            float64\n",
       "AST_PCT               float64\n",
       "AST_RATIO             float64\n",
       "AST_TOV               float64\n",
       "DEF_RATING            float64\n",
       "DREB_PCT              float64\n",
       "EFG_PCT               float64\n",
       "MIN                   float64\n",
       "NET_RATING            float64\n",
       "OFF_RATING            float64\n",
       "OREB_PCT              float64\n",
       "PACE                  float64\n",
       "PIE                   float64\n",
       "POSS                  float64\n",
       "PTS                   float64\n",
       "REB_PCT               float64\n",
       "TM_TOV_PCT            float64\n",
       "TS_PCT                float64\n",
       "USG_PCT               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690ea4a3",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133ec35b",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04eb7f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from neural_net.ipynb\n",
    "train_test_split_date = '2022-04-27 00:00:00'\n",
    "X_train = df.loc[df.GAME_DATE < train_test_split_date, ~df.columns.isin(['PLUS_MINUS'])]\n",
    "X_test = df.loc[df.GAME_DATE > train_test_split_date, ~df.columns.isin(['PLUS_MINUS'])]\n",
    "y_train = df.loc[df.GAME_DATE < train_test_split_date, ['PLUS_MINUS']]\n",
    "y_test = df.loc[df.GAME_DATE > train_test_split_date, ['PLUS_MINUS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8e2db13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      PLAYER_ID  GAME_DATE   PLAYER_NAME   AST_PCT  AST_RATIO   AST_TOV  \\\n",
       " 0          1713 2018-12-03  Vince Carter  0.123266   0.169653  0.042814   \n",
       " 1          1713 2018-12-05  Vince Carter  0.132462   0.147789  0.042814   \n",
       " 2          1713 2018-12-08  Vince Carter  0.147144   0.161434  0.057086   \n",
       " 3          1713 2018-12-12  Vince Carter  0.125686   0.163571  0.014271   \n",
       " 4          1713 2018-12-14  Vince Carter  0.125686   0.163571  0.014271   \n",
       " ...         ...        ...           ...       ...        ...       ...   \n",
       " 98794   1630846 2022-03-28  Olivier Sarr  0.102775   0.245602  0.085629   \n",
       " 98795   1630846 2022-03-30  Olivier Sarr  0.124234   0.267467  0.099900   \n",
       " 98796   1630846 2022-04-01  Olivier Sarr  0.121007   0.242643  0.114172   \n",
       " 98797   1630846 2022-04-03  Olivier Sarr  0.135689   0.253658  0.121307   \n",
       " 98798   1630846 2022-04-05  Olivier Sarr  0.123104   0.223738  0.092764   \n",
       " \n",
       "        DEF_RATING  DREB_PCT   EFG_PCT       MIN  ...  OFF_RATING  OREB_PCT  \\\n",
       " 0        0.578202  0.250375  0.402074  0.329102  ...    0.587002  0.050330   \n",
       " 1        0.546110  0.255056  0.432649  0.366260  ...    0.573205  0.064214   \n",
       " 2        0.548544  0.268539  0.466538  0.354895  ...    0.577199  0.083652   \n",
       " 3        0.554043  0.256742  0.414582  0.347681  ...    0.561224  0.065255   \n",
       " 4        0.595691  0.256742  0.396729  0.346915  ...    0.566125  0.047900   \n",
       " ...           ...       ...       ...       ...  ...         ...       ...   \n",
       " 98794    0.582259  0.182210  0.588518  0.433563  ...    0.723881  0.244707   \n",
       " 98795    0.562877  0.229026  0.612251  0.470036  ...    0.724880  0.269351   \n",
       " 98796    0.567385  0.181461  0.680992  0.519204  ...    0.721067  0.258591   \n",
       " 98797    0.526188  0.210300  0.747808  0.534075  ...    0.721249  0.198889   \n",
       " 98798    0.494726  0.215356  0.745136  0.550558  ...    0.702460  0.208608   \n",
       " \n",
       "            PACE       PIE      POSS       PTS   REB_PCT  TM_TOV_PCT    TS_PCT  \\\n",
       " 0      0.014105  0.542849  0.347285  0.421875  0.228959    0.072430  0.431366   \n",
       " 1      0.013059  0.548627  0.383484  0.437500  0.231373    0.072430  0.465736   \n",
       " 2      0.013363  0.554863  0.373303  0.437500  0.249472    0.090059  0.499260   \n",
       " 3      0.014036  0.548169  0.368778  0.445312  0.231071    0.070731  0.447864   \n",
       " 4      0.013775  0.547654  0.367647  0.474609  0.221418    0.070731  0.422377   \n",
       " ...         ...       ...       ...       ...       ...         ...       ...   \n",
       " 98794  0.008205  0.541991  0.417421  0.607422  0.252187    0.379142  0.598879   \n",
       " 98795  0.007788  0.550057  0.452489  0.613281  0.300754    0.354291  0.629547   \n",
       " 98796  0.008106  0.556350  0.503394  0.611328  0.259729    0.302889  0.703363   \n",
       " 98797  0.008570  0.572311  0.520362  0.609375  0.263952    0.246177  0.770199   \n",
       " 98798  0.008400  0.575343  0.532805  0.574219  0.272700    0.246177  0.769564   \n",
       " \n",
       "         USG_PCT  \n",
       " 0      0.376921  \n",
       " 1      0.384718  \n",
       " 2      0.418802  \n",
       " 3      0.404767  \n",
       " 4      0.418133  \n",
       " ...         ...  \n",
       " 98794  0.206728  \n",
       " 98795  0.220539  \n",
       " 98796  0.230118  \n",
       " 98797  0.255959  \n",
       " 98798  0.258409  \n",
       " \n",
       " [79708 rows x 21 columns],\n",
       "        PLAYER_ID  GAME_DATE        PLAYER_NAME   AST_PCT  AST_RATIO   AST_TOV  \\\n",
       " 456         2544 2022-10-03       LeBron James  0.432720   0.262206  0.259027   \n",
       " 457         2544 2022-10-05       LeBron James  0.448854   0.273385  0.230484   \n",
       " 458         2544 2022-10-12       LeBron James  0.429171   0.266974  0.223348   \n",
       " 459         2544 2022-10-14       LeBron James  0.400774   0.250041  0.214785   \n",
       " 460         2544 2022-10-18       LeBron James  0.440626   0.262371  0.226202   \n",
       " ...          ...        ...                ...       ...        ...       ...   \n",
       " 100079   1631323 2023-02-23  Simone Fontecchio  0.092611   0.167352  0.071357   \n",
       " 100080   1631323 2023-02-25  Simone Fontecchio  0.107293   0.190860  0.071357   \n",
       " 100081   1631323 2023-02-28  Simone Fontecchio  0.128751   0.218313  0.080919   \n",
       " 100082   1631323 2023-03-03  Simone Fontecchio  0.139561   0.228670  0.095191   \n",
       " 100083   1631323 2023-03-05  Simone Fontecchio  0.168925   0.265165  0.095191   \n",
       " \n",
       "         DEF_RATING  DREB_PCT   EFG_PCT       MIN  ...  OFF_RATING  OREB_PCT  \\\n",
       " 456       0.650410  0.322285  0.604447  0.841656  ...    0.724426  0.093023   \n",
       " 457       0.665915  0.315730  0.607013  0.797485  ...    0.722974  0.093023   \n",
       " 458       0.614712  0.331086  0.629250  0.784186  ...    0.712807  0.106907   \n",
       " 459       0.620391  0.339888  0.589053  0.729658  ...    0.699555  0.115932   \n",
       " 460       0.608852  0.370974  0.601240  0.725144  ...    0.697377  0.154460   \n",
       " ...            ...       ...       ...       ...  ...         ...       ...   \n",
       " 100079    0.566844  0.141199  0.415758  0.251965  ...    0.706635  0.133287   \n",
       " 100080    0.579735  0.141199  0.429121  0.264539  ...    0.770627  0.152725   \n",
       " 100081    0.630758  0.094382  0.375668  0.305364  ...    0.761732  0.152725   \n",
       " 100082    0.612729  0.045880  0.277635  0.358884  ...    0.773260  0.096147   \n",
       " 100083    0.641936  0.060300  0.315801  0.395518  ...    0.687574  0.096147   \n",
       " \n",
       "             PACE       PIE      POSS       PTS   REB_PCT  TM_TOV_PCT  \\\n",
       " 456     0.008474  0.608410  0.822398  0.585938  0.308296    0.230459   \n",
       " 457     0.009722  0.603890  0.787330  0.572266  0.302262    0.212829   \n",
       " 458     0.010254  0.610526  0.776018  0.576172  0.323680    0.217502   \n",
       " 459     0.010094  0.604405  0.720588  0.542969  0.333032    0.207519   \n",
       " 460     0.010898  0.613844  0.726244  0.552734  0.371342    0.200935   \n",
       " ...          ...       ...       ...       ...       ...         ...   \n",
       " 100079  0.012827  0.522883  0.263575  0.759766  0.171342    0.267842   \n",
       " 100080  0.012945  0.538387  0.277149  0.761719  0.182202    0.214741   \n",
       " 100081  0.012803  0.522654  0.319005  0.699219  0.139065    0.267842   \n",
       " 100082  0.011583  0.523112  0.369910  0.666016  0.080543    0.139550   \n",
       " 100083  0.011432  0.523112  0.408371  0.656250  0.090498    0.139550   \n",
       " \n",
       "           TS_PCT   USG_PCT  \n",
       " 456     0.639594  0.730675  \n",
       " 457     0.638959  0.710403  \n",
       " 458     0.658206  0.695032  \n",
       " 459     0.623308  0.714413  \n",
       " 460     0.639065  0.719537  \n",
       " ...          ...       ...  \n",
       " 100079  0.421003  0.387391  \n",
       " 100080  0.455690  0.367788  \n",
       " 100081  0.402813  0.317665  \n",
       " 100082  0.305626  0.312542  \n",
       " 100083  0.343380  0.350635  \n",
       " \n",
       " [20349 rows x 21 columns],\n",
       "        PLUS_MINUS\n",
       " 0           -14.9\n",
       " 1           -14.8\n",
       " 2           -13.9\n",
       " 3           -13.9\n",
       " 4           -11.5\n",
       " ...           ...\n",
       " 98794        -9.0\n",
       " 98795        -8.1\n",
       " 98796        -6.0\n",
       " 98797        -3.2\n",
       " 98798        -1.0\n",
       " \n",
       " [79708 rows x 1 columns],\n",
       "         PLUS_MINUS\n",
       " 456           -8.0\n",
       " 457           -9.7\n",
       " 458           -7.3\n",
       " 459          -10.1\n",
       " 460           -9.5\n",
       " ...            ...\n",
       " 100079         0.6\n",
       " 100080         2.3\n",
       " 100081        -0.8\n",
       " 100082        -5.3\n",
       " 100083        -5.3\n",
       " \n",
       " [20349 rows x 1 columns])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49c2054f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AST_PCT</th>\n",
       "      <th>AST_RATIO</th>\n",
       "      <th>AST_TOV</th>\n",
       "      <th>DEF_RATING</th>\n",
       "      <th>DREB_PCT</th>\n",
       "      <th>EFG_PCT</th>\n",
       "      <th>MIN</th>\n",
       "      <th>NET_RATING</th>\n",
       "      <th>OFF_RATING</th>\n",
       "      <th>OREB_PCT</th>\n",
       "      <th>PACE</th>\n",
       "      <th>PIE</th>\n",
       "      <th>POSS</th>\n",
       "      <th>PTS</th>\n",
       "      <th>REB_PCT</th>\n",
       "      <th>TM_TOV_PCT</th>\n",
       "      <th>TS_PCT</th>\n",
       "      <th>USG_PCT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>0.432720</td>\n",
       "      <td>0.262206</td>\n",
       "      <td>0.259027</td>\n",
       "      <td>0.650410</td>\n",
       "      <td>0.322285</td>\n",
       "      <td>0.604447</td>\n",
       "      <td>0.841656</td>\n",
       "      <td>0.544617</td>\n",
       "      <td>0.724426</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.008474</td>\n",
       "      <td>0.608410</td>\n",
       "      <td>0.822398</td>\n",
       "      <td>0.585938</td>\n",
       "      <td>0.308296</td>\n",
       "      <td>0.230459</td>\n",
       "      <td>0.639594</td>\n",
       "      <td>0.730675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0.448854</td>\n",
       "      <td>0.273385</td>\n",
       "      <td>0.230484</td>\n",
       "      <td>0.665915</td>\n",
       "      <td>0.315730</td>\n",
       "      <td>0.607013</td>\n",
       "      <td>0.797485</td>\n",
       "      <td>0.533373</td>\n",
       "      <td>0.722974</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.009722</td>\n",
       "      <td>0.603890</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.572266</td>\n",
       "      <td>0.302262</td>\n",
       "      <td>0.212829</td>\n",
       "      <td>0.638959</td>\n",
       "      <td>0.710403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>0.429171</td>\n",
       "      <td>0.266974</td>\n",
       "      <td>0.223348</td>\n",
       "      <td>0.614712</td>\n",
       "      <td>0.331086</td>\n",
       "      <td>0.629250</td>\n",
       "      <td>0.784186</td>\n",
       "      <td>0.560646</td>\n",
       "      <td>0.712807</td>\n",
       "      <td>0.106907</td>\n",
       "      <td>0.010254</td>\n",
       "      <td>0.610526</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.576172</td>\n",
       "      <td>0.323680</td>\n",
       "      <td>0.217502</td>\n",
       "      <td>0.658206</td>\n",
       "      <td>0.695032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>0.400774</td>\n",
       "      <td>0.250041</td>\n",
       "      <td>0.214785</td>\n",
       "      <td>0.620391</td>\n",
       "      <td>0.339888</td>\n",
       "      <td>0.589053</td>\n",
       "      <td>0.729658</td>\n",
       "      <td>0.548086</td>\n",
       "      <td>0.699555</td>\n",
       "      <td>0.115932</td>\n",
       "      <td>0.010094</td>\n",
       "      <td>0.604405</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.542969</td>\n",
       "      <td>0.333032</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.623308</td>\n",
       "      <td>0.714413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>0.440626</td>\n",
       "      <td>0.262371</td>\n",
       "      <td>0.226202</td>\n",
       "      <td>0.608852</td>\n",
       "      <td>0.370974</td>\n",
       "      <td>0.601240</td>\n",
       "      <td>0.725144</td>\n",
       "      <td>0.554306</td>\n",
       "      <td>0.697377</td>\n",
       "      <td>0.154460</td>\n",
       "      <td>0.010898</td>\n",
       "      <td>0.613844</td>\n",
       "      <td>0.726244</td>\n",
       "      <td>0.552734</td>\n",
       "      <td>0.371342</td>\n",
       "      <td>0.200935</td>\n",
       "      <td>0.639065</td>\n",
       "      <td>0.719537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100079</th>\n",
       "      <td>0.092611</td>\n",
       "      <td>0.167352</td>\n",
       "      <td>0.071357</td>\n",
       "      <td>0.566844</td>\n",
       "      <td>0.141199</td>\n",
       "      <td>0.415758</td>\n",
       "      <td>0.251965</td>\n",
       "      <td>0.588337</td>\n",
       "      <td>0.706635</td>\n",
       "      <td>0.133287</td>\n",
       "      <td>0.012827</td>\n",
       "      <td>0.522883</td>\n",
       "      <td>0.263575</td>\n",
       "      <td>0.759766</td>\n",
       "      <td>0.171342</td>\n",
       "      <td>0.267842</td>\n",
       "      <td>0.421003</td>\n",
       "      <td>0.387391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100080</th>\n",
       "      <td>0.107293</td>\n",
       "      <td>0.190860</td>\n",
       "      <td>0.071357</td>\n",
       "      <td>0.579735</td>\n",
       "      <td>0.141199</td>\n",
       "      <td>0.429121</td>\n",
       "      <td>0.264539</td>\n",
       "      <td>0.622010</td>\n",
       "      <td>0.770627</td>\n",
       "      <td>0.152725</td>\n",
       "      <td>0.012945</td>\n",
       "      <td>0.538387</td>\n",
       "      <td>0.277149</td>\n",
       "      <td>0.761719</td>\n",
       "      <td>0.182202</td>\n",
       "      <td>0.214741</td>\n",
       "      <td>0.455690</td>\n",
       "      <td>0.367788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100081</th>\n",
       "      <td>0.128751</td>\n",
       "      <td>0.218313</td>\n",
       "      <td>0.080919</td>\n",
       "      <td>0.630758</td>\n",
       "      <td>0.094382</td>\n",
       "      <td>0.375668</td>\n",
       "      <td>0.305364</td>\n",
       "      <td>0.582356</td>\n",
       "      <td>0.761732</td>\n",
       "      <td>0.152725</td>\n",
       "      <td>0.012803</td>\n",
       "      <td>0.522654</td>\n",
       "      <td>0.319005</td>\n",
       "      <td>0.699219</td>\n",
       "      <td>0.139065</td>\n",
       "      <td>0.267842</td>\n",
       "      <td>0.402813</td>\n",
       "      <td>0.317665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100082</th>\n",
       "      <td>0.139561</td>\n",
       "      <td>0.228670</td>\n",
       "      <td>0.095191</td>\n",
       "      <td>0.612729</td>\n",
       "      <td>0.045880</td>\n",
       "      <td>0.277635</td>\n",
       "      <td>0.358884</td>\n",
       "      <td>0.601974</td>\n",
       "      <td>0.773260</td>\n",
       "      <td>0.096147</td>\n",
       "      <td>0.011583</td>\n",
       "      <td>0.523112</td>\n",
       "      <td>0.369910</td>\n",
       "      <td>0.666016</td>\n",
       "      <td>0.080543</td>\n",
       "      <td>0.139550</td>\n",
       "      <td>0.305626</td>\n",
       "      <td>0.312542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100083</th>\n",
       "      <td>0.168925</td>\n",
       "      <td>0.265165</td>\n",
       "      <td>0.095191</td>\n",
       "      <td>0.641936</td>\n",
       "      <td>0.060300</td>\n",
       "      <td>0.315801</td>\n",
       "      <td>0.395518</td>\n",
       "      <td>0.526136</td>\n",
       "      <td>0.687574</td>\n",
       "      <td>0.096147</td>\n",
       "      <td>0.011432</td>\n",
       "      <td>0.523112</td>\n",
       "      <td>0.408371</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.090498</td>\n",
       "      <td>0.139550</td>\n",
       "      <td>0.343380</td>\n",
       "      <td>0.350635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20349 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AST_PCT  AST_RATIO   AST_TOV  DEF_RATING  DREB_PCT   EFG_PCT  \\\n",
       "456     0.432720   0.262206  0.259027    0.650410  0.322285  0.604447   \n",
       "457     0.448854   0.273385  0.230484    0.665915  0.315730  0.607013   \n",
       "458     0.429171   0.266974  0.223348    0.614712  0.331086  0.629250   \n",
       "459     0.400774   0.250041  0.214785    0.620391  0.339888  0.589053   \n",
       "460     0.440626   0.262371  0.226202    0.608852  0.370974  0.601240   \n",
       "...          ...        ...       ...         ...       ...       ...   \n",
       "100079  0.092611   0.167352  0.071357    0.566844  0.141199  0.415758   \n",
       "100080  0.107293   0.190860  0.071357    0.579735  0.141199  0.429121   \n",
       "100081  0.128751   0.218313  0.080919    0.630758  0.094382  0.375668   \n",
       "100082  0.139561   0.228670  0.095191    0.612729  0.045880  0.277635   \n",
       "100083  0.168925   0.265165  0.095191    0.641936  0.060300  0.315801   \n",
       "\n",
       "             MIN  NET_RATING  OFF_RATING  OREB_PCT      PACE       PIE  \\\n",
       "456     0.841656    0.544617    0.724426  0.093023  0.008474  0.608410   \n",
       "457     0.797485    0.533373    0.722974  0.093023  0.009722  0.603890   \n",
       "458     0.784186    0.560646    0.712807  0.106907  0.010254  0.610526   \n",
       "459     0.729658    0.548086    0.699555  0.115932  0.010094  0.604405   \n",
       "460     0.725144    0.554306    0.697377  0.154460  0.010898  0.613844   \n",
       "...          ...         ...         ...       ...       ...       ...   \n",
       "100079  0.251965    0.588337    0.706635  0.133287  0.012827  0.522883   \n",
       "100080  0.264539    0.622010    0.770627  0.152725  0.012945  0.538387   \n",
       "100081  0.305364    0.582356    0.761732  0.152725  0.012803  0.522654   \n",
       "100082  0.358884    0.601974    0.773260  0.096147  0.011583  0.523112   \n",
       "100083  0.395518    0.526136    0.687574  0.096147  0.011432  0.523112   \n",
       "\n",
       "            POSS       PTS   REB_PCT  TM_TOV_PCT    TS_PCT   USG_PCT  \n",
       "456     0.822398  0.585938  0.308296    0.230459  0.639594  0.730675  \n",
       "457     0.787330  0.572266  0.302262    0.212829  0.638959  0.710403  \n",
       "458     0.776018  0.576172  0.323680    0.217502  0.658206  0.695032  \n",
       "459     0.720588  0.542969  0.333032    0.207519  0.623308  0.714413  \n",
       "460     0.726244  0.552734  0.371342    0.200935  0.639065  0.719537  \n",
       "...          ...       ...       ...         ...       ...       ...  \n",
       "100079  0.263575  0.759766  0.171342    0.267842  0.421003  0.387391  \n",
       "100080  0.277149  0.761719  0.182202    0.214741  0.455690  0.367788  \n",
       "100081  0.319005  0.699219  0.139065    0.267842  0.402813  0.317665  \n",
       "100082  0.369910  0.666016  0.080543    0.139550  0.305626  0.312542  \n",
       "100083  0.408371  0.656250  0.090498    0.139550  0.343380  0.350635  \n",
       "\n",
       "[20349 rows x 18 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_catless = X_train.loc[:, ~X_train.columns.isin(['GAME_DATE', 'PLAYER_ID', 'PLAYER_NAME'])]\n",
    "X_test_catless = X_test.loc[:, ~X_test.columns.isin(['GAME_DATE', 'PLAYER_ID', 'PLAYER_NAME'])]\n",
    "X_test_catless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f4ae69d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain_reg = DMatrix(X_train_dateless, y_train, enable_categorical=True)\n",
    "dtest_reg = DMatrix(X_test_dateless, y_test, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6296f3",
   "metadata": {},
   "source": [
    "## 3.2 XGBoost with Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbf0d794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossValRMSLE:                                                        \n",
      "0.6610243934347652                                                    \n",
      "CrossValRMSLE:                                                        \n",
      "0.5687240984788143                                                    \n",
      "CrossValRMSLE:                                                        \n",
      "0.7579644600194874                                                    \n",
      "  3%| | 3/100 [00:57<31:08, 19.26s/trial, best loss: 0.568724098478814\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 38\u001b[0m\n\u001b[1;32m     27\u001b[0m space \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m : hp\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m)),\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m : hp\u001b[38;5;241m.\u001b[39mquniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.01\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolsample_bytree\u001b[39m\u001b[38;5;124m'\u001b[39m : hp\u001b[38;5;241m.\u001b[39mquniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolsample_bytree\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m     35\u001b[0m }\n\u001b[1;32m     37\u001b[0m trials \u001b[38;5;241m=\u001b[39m Trials()\n\u001b[0;32m---> 38\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m            \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest: \u001b[39m\u001b[38;5;124m\"\u001b[39m, best)\n",
      "File \u001b[0;32m~/.pyenv/versions/nba_betting_analysis/lib/python3.10/site-packages/hyperopt/fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[0;32m~/.pyenv/versions/nba_betting_analysis/lib/python3.10/site-packages/hyperopt/base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[0;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/nba_betting_analysis/lib/python3.10/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/nba_betting_analysis/lib/python3.10/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/nba_betting_analysis/lib/python3.10/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/nba_betting_analysis/lib/python3.10/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/.pyenv/versions/nba_betting_analysis/lib/python3.10/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[0;32mIn[18], line 16\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(space)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(space):\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#warnings.filterwarnings(action='ignore', category=DeprecationWarning)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     hyperopt_regressor \u001b[38;5;241m=\u001b[39m XGBRegressor(n_estimators \u001b[38;5;241m=\u001b[39m space[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m                             max_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(space[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m      8\u001b[0m                             learning_rate \u001b[38;5;241m=\u001b[39m space[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m                             objective \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg:pseudohubererror\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     14\u001b[0m                             )\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mhyperopt_regressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_catless\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Applying k-Fold Cross Validation\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n",
      "File \u001b[0;32m~/.pyenv/versions/nba_betting_analysis/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/nba_betting_analysis/lib/python3.10/site-packages/xgboost/sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m (\n\u001b[1;32m   1017\u001b[0m     model,\n\u001b[1;32m   1018\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1024\u001b[0m )\n\u001b[0;32m-> 1025\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/nba_betting_analysis/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/nba_betting_analysis/lib/python3.10/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/nba_betting_analysis/lib/python3.10/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# BASED ON: https://www.kaggle.com/code/henrylidgley/xgboost-with-hyperopt-tuning\n",
    "\n",
    "def objective(space):\n",
    "\n",
    "    #warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "    hyperopt_regressor = XGBRegressor(n_estimators = space['n_estimators'],\n",
    "                            max_depth = int(space['max_depth']),\n",
    "                            learning_rate = space['learning_rate'],\n",
    "                            gamma = space['gamma'],\n",
    "                            min_child_weight = space['min_child_weight'],\n",
    "                            subsample = space['subsample'],\n",
    "                            colsample_bytree = space['colsample_bytree'],\n",
    "                            objective = 'reg:pseudohubererror'\n",
    "                            )\n",
    "    \n",
    "    hyperopt_regressor.fit(X_train_catless, y_train)\n",
    "\n",
    "    # Applying k-Fold Cross Validation\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    msle = cross_val_score(estimator = hyperopt_regressor, X = X_train_catless, y = y_train, cv = 10, n_jobs=-1)\n",
    "    CrossValRMSLE = np.sqrt(msle.mean())\n",
    "\n",
    "    print(\"CrossValRMSLE: \", CrossValRMSLE)\n",
    "\n",
    "    return{'loss': CrossValRMSLE, 'status': STATUS_OK }\n",
    "\n",
    "space = {\n",
    "    'max_depth' : hp.choice('max_depth', range(5, 50, 1)),\n",
    "    'learning_rate' : hp.quniform('learning_rate', 0.01, 0.5, 0.01),\n",
    "    'n_estimators' : hp.choice('n_estimators', range(20, 100, 5)),\n",
    "    'gamma' : hp.quniform('gamma', 0, 0.50, 0.01),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 1, 10, 1),\n",
    "    'subsample' : hp.quniform('subsample', 0.1, 1, 0.01),\n",
    "    'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1.0, 0.01)\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100,\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71e3ca2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 2,\n",
       " 'tid': 0,\n",
       " 'spec': None,\n",
       " 'result': {'loss': 0.6610243934347652, 'status': 'ok'},\n",
       " 'misc': {'tid': 0,\n",
       "  'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "  'workdir': None,\n",
       "  'idxs': {'colsample_bytree': [0],\n",
       "   'gamma': [0],\n",
       "   'learning_rate': [0],\n",
       "   'max_depth': [0],\n",
       "   'min_child_weight': [0],\n",
       "   'n_estimators': [0],\n",
       "   'subsample': [0]},\n",
       "  'vals': {'colsample_bytree': [0.53],\n",
       "   'gamma': [0.48],\n",
       "   'learning_rate': [0.19],\n",
       "   'max_depth': [27],\n",
       "   'min_child_weight': [2.0],\n",
       "   'n_estimators': [3],\n",
       "   'subsample': [0.56]}},\n",
       " 'exp_key': None,\n",
       " 'owner': None,\n",
       " 'version': 0,\n",
       " 'book_time': datetime.datetime(2023, 3, 10, 3, 10, 24, 52000),\n",
       " 'refresh_time': datetime.datetime(2023, 3, 10, 3, 10, 46, 914000)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.trials[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "432b2bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 33,\n",
       " 'objective': 'reg:squarederror',\n",
       " 'max_depth': 50,\n",
       " 'max_leaves': None,\n",
       " 'max_bin': None,\n",
       " 'grow_policy': None,\n",
       " 'learning_rate': 0.06,\n",
       " 'verbosity': None,\n",
       " 'booster': None,\n",
       " 'tree_method': None,\n",
       " 'gamma': 0.35000000000000003,\n",
       " 'min_child_weight': 6.0,\n",
       " 'max_delta_step': None,\n",
       " 'subsample': 0.96,\n",
       " 'sampling_method': None,\n",
       " 'colsample_bytree': 0.53,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'base_score': None,\n",
       " 'missing': nan,\n",
       " 'num_parallel_tree': None,\n",
       " 'random_state': None,\n",
       " 'n_jobs': None,\n",
       " 'monotone_constraints': None,\n",
       " 'interaction_constraints': None,\n",
       " 'importance_type': None,\n",
       " 'gpu_id': None,\n",
       " 'validate_parameters': None,\n",
       " 'predictor': None,\n",
       " 'enable_categorical': False,\n",
       " 'feature_types': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'eval_metric': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'callbacks': None,\n",
       " '_Booster': <xgboost.core.Booster at 0x302ea6a40>}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperopt_regressor.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "52703eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.53,\n",
       " 'gamma': 0.35000000000000003,\n",
       " 'learning_rate': 0.06,\n",
       " 'max_depth': 0,\n",
       " 'min_child_weight': 6.0,\n",
       " 'n_estimators': 33,\n",
       " 'subsample': 0.96}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2c86db2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6641830208272335\n"
     ]
    }
   ],
   "source": [
    "regressor = XGBRegressor(n_estimators = best['n_estimators'],\n",
    "                            max_depth = 50,#best['max_depth'],\n",
    "                            learning_rate = best['learning_rate'],\n",
    "                            gamma = best['gamma'],\n",
    "                            min_child_weight = best['min_child_weight'],\n",
    "                            subsample = best['subsample'],\n",
    "                            colsample_bytree = best['colsample_bytree'],\n",
    "                            objective='reg:squarederror'\n",
    "                            )\n",
    "\n",
    "regressor.fit(X_train_catless, y_train)\n",
    "print(np.sqrt(regressor.score(X_test_catless, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a4cbf828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>-8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>-9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>-7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>-10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>-9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100079</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100080</th>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100081</th>\n",
       "      <td>-0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100082</th>\n",
       "      <td>-5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100083</th>\n",
       "      <td>-5.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20349 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PLUS_MINUS\n",
       "456           -8.0\n",
       "457           -9.7\n",
       "458           -7.3\n",
       "459          -10.1\n",
       "460           -9.5\n",
       "...            ...\n",
       "100079         0.6\n",
       "100080         2.3\n",
       "100081        -0.8\n",
       "100082        -5.3\n",
       "100083        -5.3\n",
       "\n",
       "[20349 rows x 1 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d51f130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "mses = cross_val_score(estimator = regressor, X=X_train_catless, y = y_train, cv = 10)\n",
    "CrossValRMSE = np.sqrt(mses.mean())\n",
    "print(\"Final CrossValRMSE: \", CrossValRMSE)\n",
    "\n",
    "CrossValSTD = mses.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "147b1913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test_catless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c43a46cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6641830208272335 0.04867153087004938\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(regressor.score(X_test_catless, y_test)), CrossValSTD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "97e4fadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20349,)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_values = np.array(y_test.values)\n",
    "y_test_values = y_test_values.ravel()\n",
    "y_test_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "65d8eac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20349,)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "261a5de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(pd.DataFrame({'y_pred': y_pred, 'y_true': y_test_values}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73288bf6",
   "metadata": {},
   "source": [
    "“reg:squaredlogerror“, TRY THIS ONE\n",
    "“reg:logistic“, \n",
    "“reg:pseudohubererror“, \n",
    "“reg:gamma“, \n",
    "and “reg:tweedie“."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
